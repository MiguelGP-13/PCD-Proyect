{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "763c7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from keras.applications.xception import preprocess_input as xception_preprocess\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Desactiva todas las GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab15a4a2",
   "metadata": {},
   "source": [
    "## Evaluación binaria con conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50de79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_path, preprocess_fn, test_dir=\"data/processed/test\", image_size=(224, 224)):\n",
    "    # Cargar dataset desde carpeta test\n",
    "    test_ds = keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        image_size=image_size,   # ajusta al tamaño que tu modelo espera\n",
    "        batch_size=32,\n",
    "        shuffle=False            # importante para que las etiquetas correspondan\n",
    "    )\n",
    "\n",
    "    # Clases detectadas\n",
    "    class_names = test_ds.class_names\n",
    "    print(\"Clases detectadas:\", class_names)\n",
    "\n",
    "\n",
    "    # Mapear dataset con la función de preprocesamiento\n",
    "    test_ds = test_ds.map(lambda x, y: (preprocess_fn(x), y))\n",
    "\n",
    "    # Cargar modelo entrenado\n",
    "    if type(model_path) == str:\n",
    "        model = keras.models.load_model(model_path)\n",
    "    else:\n",
    "        model = model_path\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(test_ds)\n",
    "\n",
    "    # Si tu modelo tiene salida softmax (2 neuronas)\n",
    "    if y_pred_probs.shape[1] > 1:\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    else:  # salida sigmoid (1 neurona)\n",
    "        y_pred = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "    # Etiquetas verdaderas\n",
    "    y_true = np.concatenate([y.numpy() for _, y in test_ds], axis=0)\n",
    "\n",
    "    # Reporte de clasificación\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734c4ed",
   "metadata": {},
   "source": [
    "### Modelo entrenado desde 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd64aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1002 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['benignas', 'malignas']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 12:26:43.315403: I external/local_xla/xla/service/service.cc:163] XLA service 0x745bec00b880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-29 12:26:43.315429: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Host, Default Version\n",
      "2025-11-29 12:26:43.337833: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1764415603.523456   38543 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    benignas       0.84      0.91      0.87       807\n",
      "    malignas       0.43      0.27      0.33       195\n",
      "\n",
      "    accuracy                           0.79      1002\n",
      "   macro avg       0.63      0.59      0.60      1002\n",
      "weighted avg       0.76      0.79      0.77      1002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 12:26:50.469721: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(test_model(\"models/classifier/new_model_11_20_h12_29.keras\", lambda x: x/255.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bd6439",
   "metadata": {},
   "source": [
    "### Modelo partiendo de VGG (imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4173109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1002 files belonging to 2 classes.\n",
      "Clases detectadas: ['benignas', 'malignas']\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    benignas       0.94      0.89      0.92       807\n",
      "    malignas       0.63      0.75      0.69       195\n",
      "\n",
      "    accuracy                           0.87      1002\n",
      "   macro avg       0.78      0.82      0.80      1002\n",
      "weighted avg       0.88      0.87      0.87      1002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 12:27:44.115826: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(test_model(\"models/classifier/vgg16_finetuned_11_25_11_17.keras\", vgg16_preprocess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977ced6",
   "metadata": {},
   "source": [
    "### Modelo partiendo de ResNet50 (imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0855298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1002 files belonging to 2 classes.\n",
      "Clases detectadas: ['benignas', 'malignas']\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 726ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    benignas       0.96      0.81      0.88       807\n",
      "    malignas       0.52      0.85      0.64       195\n",
      "\n",
      "    accuracy                           0.82      1002\n",
      "   macro avg       0.74      0.83      0.76      1002\n",
      "weighted avg       0.87      0.82      0.83      1002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_model(\"models/classifier/resnet50_finetuned_11_26_12_13.keras\", resnet_preprocess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f61255",
   "metadata": {},
   "source": [
    "### Modelo partiendo de Xception (imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5de9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1002 files belonging to 2 classes.\n",
      "Clases detectadas: ['benignas', 'malignas']\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 539ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    benignas       0.90      0.81      0.85       807\n",
      "    malignas       0.44      0.61      0.51       195\n",
      "\n",
      "    accuracy                           0.77      1002\n",
      "   macro avg       0.67      0.71      0.68      1002\n",
      "weighted avg       0.81      0.77      0.79      1002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 12:28:37.274809: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(test_model(\"models/classifier/inceptionv3_finetuned_11_26_13_17.keras\", xception_preprocess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8f75ca",
   "metadata": {},
   "source": [
    "## Evaluación Malignas con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a96d78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM=128\n",
    "IMG_SIZE=(128,128)\n",
    "def contrastive_encoder(input_shape=(IMG_SIZE[0],IMG_SIZE[1],3), embedding_dim=EMBED_DIM):\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # Bloque 1\n",
    "    x = keras.layers.Conv2D(64, 3, padding='same', use_bias=False)(inputs)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    s = keras.layers.Conv2D(64, 1, padding='same', use_bias=False)(inputs)\n",
    "    s = keras.layers.BatchNormalization()(s)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "    # Bloque 2\n",
    "    y = keras.layers.Conv2D(128, 3, padding='same', use_bias=False)(x)\n",
    "    y = keras.layers.BatchNormalization()(y)\n",
    "    y = keras.layers.ReLU()(y)\n",
    "    y = keras.layers.Conv2D(128, 3, padding='same', use_bias=False)(y)\n",
    "    y = keras.layers.BatchNormalization()(y)\n",
    "    s2 = keras.layers.Conv2D(128, 1, padding='same', use_bias=False)(x)\n",
    "    s2 = keras.layers.BatchNormalization()(s2)\n",
    "    y = keras.layers.Add()([y, s2])\n",
    "    y = keras.layers.ReLU()(y)\n",
    "    y = keras.layers.MaxPooling2D()(y)\n",
    "\n",
    "    # Bloque 3\n",
    "    z = keras.layers.Conv2D(256, 3, padding='same', use_bias=False)(y)\n",
    "    z = keras.layers.BatchNormalization()(z)\n",
    "    z = keras.layers.ReLU()(z)\n",
    "    z = keras.layers.Conv2D(256, 3, padding='same', use_bias=False)(z)\n",
    "    z = keras.layers.BatchNormalization()(z)\n",
    "    s3 = keras.layers.Conv2D(256, 1, padding='same', use_bias=False)(y)\n",
    "    s3 = keras.layers.BatchNormalization()(s3)\n",
    "    z = keras.layers.Add()([z, s3])\n",
    "    z = keras.layers.ReLU()(z)\n",
    "\n",
    "    z = keras.layers.GlobalAveragePooling2D()(z)\n",
    "    z = keras.layers.Dense(512, activation='relu')(z)\n",
    "    z = keras.layers.BatchNormalization()(z)\n",
    "\n",
    "    # Proyección (cabeza contrastiva)timestamps\n",
    "    p = keras.layers.Dense(embedding_dim, activation='relu')(z)\n",
    "    p = keras.layers.Dense(embedding_dim)(p)\n",
    "    outputs = keras.layers.Lambda(\n",
    "    lambda t: tf.math.l2_normalize(t, axis=1),\n",
    "    name=\"proj_norm\",\n",
    "    output_shape=(embedding_dim,))(p)\n",
    "\n",
    "\n",
    "    return keras.models.Model(inputs, outputs, name=\"ContrastiveEncoder\")\n",
    "\n",
    "def classifier(input_shape=(IMG_SIZE[0],IMG_SIZE[1],3), embedding_dim=EMBED_DIM, num_classes=3):\n",
    "    e = contrastive_encoder(input_shape, embedding_dim)\n",
    "    x = e.output\n",
    "    clf = keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return keras.models.Model(e.input, clf)\n",
    "\n",
    "def test_knn(model_path, encoder_path, preprocess_fn, test_dir=\"data/malignas_classes/test\"):\n",
    "    # Cargar dataset desde carpeta test\n",
    "    test_ds = keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        image_size=(128, 128),   # ajusta al tamaño que tu encoder espera\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Clases detectadas\n",
    "    class_names = test_ds.class_names\n",
    "    print(\"Clases detectadas:\", class_names)\n",
    "\n",
    "    # Mapear dataset con la función de preprocesamiento\n",
    "    test_ds = test_ds.map(lambda x, y: (preprocess_fn(x), y))\n",
    "\n",
    "    # Cargar el modelo KNN entrenado\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        knn_loaded = pickle.load(f)\n",
    "    # Cargar encoder\n",
    "    encoder = contrastive_encoder(\n",
    "    input_shape=(128,128, 3),\n",
    "    embedding_dim=128\n",
    "    )\n",
    "\n",
    "    encoder.load_weights(encoder_path)\n",
    "\n",
    "    # Extraer embeddings con el encoder\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch_x, batch_y in test_ds:\n",
    "        emb = encoder.predict(batch_x)   # generar embeddings\n",
    "        embeddings.append(emb)\n",
    "        labels.append(batch_y.numpy())\n",
    "\n",
    "    X_test = np.concatenate(embeddings, axis=0)\n",
    "    y_true = np.concatenate(labels, axis=0)\n",
    "\n",
    "    # Predicciones con el KNN cargado\n",
    "    y_pred = knn_loaded.predict(X_test)\n",
    "\n",
    "    # Reporte de clasificación\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd3bd3",
   "metadata": {},
   "source": [
    "### KNN con SupConLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248217c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['akiec', 'bcc', 'mel']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/python3.12/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 40 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x745bdfd31080> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.37      0.35      0.36        31\n",
      "         bcc       0.64      0.43      0.52        53\n",
      "         mel       0.79      0.92      0.85       111\n",
      "\n",
      "    accuracy                           0.70       195\n",
      "   macro avg       0.60      0.57      0.58       195\n",
      "weighted avg       0.68      0.70      0.68       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado desde el archivo\n",
    "print(test_knn(\"models/malignClassifier/knn_model_11_29_h11_36.pkl\",\"models/encoder/encoder_11_26_h14_27.keras\",lambda x: x/255.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dafe018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 files belonging to 3 classes.\n",
      "Clases detectadas: ['akiec', 'bcc', 'mel']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/python3.12/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x745c00e305e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.83      0.32      0.47        31\n",
      "         bcc       0.84      0.77      0.80        53\n",
      "         mel       0.81      0.98      0.89       111\n",
      "\n",
      "    accuracy                           0.82       195\n",
      "   macro avg       0.83      0.69      0.72       195\n",
      "weighted avg       0.82      0.82      0.80       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_knn(\"models/malignClassifier/knn_model_finetunedEncoder_11_29_h11_35.pkl\",\"models/encoder/encoder_finetuned_11_26_h15_34.keras\",lambda x: x/255.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7eb94cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 files belonging to 3 classes.\n",
      "Clases detectadas: ['akiec', 'bcc', 'mel']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/python3.12/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.53      0.32      0.40        31\n",
      "         bcc       0.82      0.70      0.76        53\n",
      "         mel       0.83      0.98      0.90       111\n",
      "\n",
      "    accuracy                           0.80       195\n",
      "   macro avg       0.73      0.67      0.69       195\n",
      "weighted avg       0.78      0.80      0.78       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_knn(\"models/malignClassifier/knn_model_11_29_h11_36.pkl\",\"models/encoder/encoder_finetuned_11_26_h15_34.keras\",lambda x: x/255.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696580c2",
   "metadata": {},
   "source": [
    "### Modelo clásico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "447b94d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 195 files belonging to 3 classes.\n",
      "Clases detectadas: ['akiec', 'bcc', 'mel']\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 521ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.60      0.39      0.47        31\n",
      "         bcc       0.83      0.72      0.77        53\n",
      "         mel       0.84      0.97      0.90       111\n",
      "\n",
      "    accuracy                           0.81       195\n",
      "   macro avg       0.75      0.69      0.71       195\n",
      "weighted avg       0.80      0.81      0.80       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = classifier(\n",
    "    input_shape=(128,128, 3),\n",
    "    embedding_dim=128, \n",
    "    num_classes=3\n",
    "    )\n",
    "\n",
    "m.load_weights(\"models/malignClassifier/classifier_11_26_h15_34.keras\")\n",
    "print(test_model(m, lambda x: x/255, \"data/malignas_classes/test\", image_size=(128,128)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1dc02d",
   "metadata": {},
   "source": [
    "## Evaluación de pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06decd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_binary_model(model_path, preprocess_fn, image_size=(224,224)):\n",
    "    model = keras.models.load_model(model_path)\n",
    "    return model, preprocess_fn, image_size\n",
    "\n",
    "def load_knn_pipeline(knn_path, encoder_path, preprocess_fn, image_size=(128,128)):\n",
    "    # Cargar KNN\n",
    "    with open(knn_path, \"rb\") as f:\n",
    "        knn_loaded = pickle.load(f)\n",
    "    # Cargar encoder\n",
    "    encoder = contrastive_encoder(\n",
    "        input_shape=(image_size[0], image_size[1], 3),\n",
    "        embedding_dim=128\n",
    "    )\n",
    "    encoder.load_weights(encoder_path)\n",
    "    return knn_loaded, encoder, preprocess_fn, image_size\n",
    "\n",
    "def test_pipeline(binary_model_path, binary_preprocess, knn_path, encoder_path, knn_preprocess,\n",
    "                  test_dir=\"data/full/test\"):\n",
    "    # Dataset completo con todas las clases (para binario)\n",
    "    test_ds = keras.utils.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        image_size=(224,224),   # tamaño para el binario\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "    class_names = test_ds.class_names\n",
    "    print(\"Clases detectadas:\", class_names)\n",
    "\n",
    "    # Mapear dataset con preprocesamiento binario\n",
    "    test_ds_bin = test_ds.map(lambda x, y: (binary_preprocess(x), y))\n",
    "\n",
    "    # Cargar modelos\n",
    "    binary_model = keras.models.load_model(binary_model_path)\n",
    "    encoder = contrastive_encoder(input_shape=(128,128,3), embedding_dim=128)\n",
    "    encoder.load_weights(encoder_path)\n",
    "    with open(knn_path, \"rb\") as f:\n",
    "        knn = pickle.load(f)\n",
    "\n",
    "    # Predicciones binario\n",
    "    y_pred_probs = binary_model.predict(test_ds_bin)\n",
    "    if y_pred_probs.shape[1] > 1:\n",
    "        y_pred_bin = np.argmax(y_pred_probs, axis=1)\n",
    "    else:\n",
    "        y_pred_bin = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "    # Etiquetas verdaderas\n",
    "    y_true = np.concatenate([y.numpy() for _, y in test_ds_bin], axis=0)\n",
    "\n",
    "    # Indices de malignas\n",
    "    malign_indices = np.where(y_pred_bin == 1)[0]\n",
    "\n",
    "    # --- SOLO malignas ---\n",
    "    file_paths = np.array(test_ds.file_paths)[malign_indices]\n",
    "\n",
    "    # Crear dataset solo con imágenes malignas\n",
    "    malign_ds = tf.data.Dataset.from_tensor_slices(file_paths)\n",
    "    malign_ds = malign_ds.map(\n",
    "        lambda path: (tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(path)), (128,128)), 0)\n",
    "    )\n",
    "    malign_ds = malign_ds.map(lambda x,y: (knn_preprocess(x), y)).batch(32)\n",
    "\n",
    "    # Embeddings solo de malignas\n",
    "    X_test = encoder.predict(malign_ds.map(lambda x,y: x), verbose=1)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "    # Mapeo de índices KNN a nombres de clase (orden alfabético)\n",
    "    knn_classes = [\"akiec\",\"bcc\",\"mel\"]\n",
    "    y_pred_knn_labels = [knn_classes[idx] for idx in y_pred_knn]\n",
    "\n",
    "    # Fusionar resultados:\n",
    "    final_pred = []\n",
    "    malign_counter = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_pred_bin[i] == 0:\n",
    "            final_pred.append(class_names.index(\"benignas\"))\n",
    "        else:\n",
    "            knn_label = y_pred_knn_labels[malign_counter]\n",
    "            final_pred.append(class_names.index(knn_label))\n",
    "            malign_counter += 1\n",
    "\n",
    "    # Reporte final\n",
    "    report = classification_report(y_true, final_pred, target_names=class_names)#, zero_division=0)\n",
    "    return report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec0b0d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1002 files belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['akiec', 'bcc', 'benignas', 'mel']\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 206ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.24      0.30      0.27        33\n",
      "         bcc       0.19      0.45      0.26        51\n",
      "    benignas       0.91      0.62      0.74       807\n",
      "         mel       0.24      0.62      0.35       111\n",
      "\n",
      "    accuracy                           0.60      1002\n",
      "   macro avg       0.39      0.50      0.41      1002\n",
      "weighted avg       0.78      0.60      0.66      1002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 17:34:44.670919: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(test_model(\"models/full/full_model_11_29_h16_08.keras\",lambda x: x/255,\"data/full/test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81972a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1002 files belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['akiec', 'bcc', 'benignas', 'mel']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/python3.12/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 488ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.48      0.30      0.37        33\n",
      "         bcc       0.56      0.49      0.52        51\n",
      "    benignas       0.91      0.78      0.84       807\n",
      "         mel       0.30      0.66      0.41       111\n",
      "\n",
      "    accuracy                           0.74      1002\n",
      "   macro avg       0.56      0.56      0.54      1002\n",
      "weighted avg       0.81      0.74      0.76      1002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_pipeline(\"models/classifier/vgg16_finetuned_11_25_11_17.keras\",vgg16_preprocess,\n",
    "              \"models/malignClassifier/knn_model_finetunedEncoder_11_29_h11_35.pkl\",\n",
    "              \"models/encoder/encoder_finetuned_11_26_h15_34.keras\",lambda x: x/255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40dfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
