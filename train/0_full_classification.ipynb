{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36e4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, \n",
    "                                     BatchNormalization, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90cb3eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8517 images belonging to 4 classes.\n",
      "Found 496 images belonging to 4 classes.\n",
      "2    399\n",
      "3     55\n",
      "1     26\n",
      "0     16\n",
      "Name: count, dtype: int64\n",
      "2    6855\n",
      "3     947\n",
      "1     437\n",
      "0     278\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/full/train\"\n",
    "val_dir = \"../data/full/val\"\n",
    "\n",
    "# Augmentación para entrenamiento\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8,1.2],\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True, # Contempla manchas simétricas\n",
    ")\n",
    "\n",
    "# Generador de entrenamiento\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "datagen_val = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "val_generator = datagen_val.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(pd.Series(val_generator.classes).value_counts())\n",
    "print(pd.Series(train_generator.classes).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a11eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 7.659172661870503, 1: 4.872425629290618, 2: 0.31061269146608317, 3: 2.248416050686378}\n"
     ]
    }
   ],
   "source": [
    "labels = train_generator.classes\n",
    "\n",
    "# Calculamos los pesos\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "# Lo convertimos en diccionario para Keras\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "204809e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[0.57254905, 0.3529412 , 0.4039216 ],\n",
       "          [0.5921569 , 0.36862746, 0.427451  ],\n",
       "          [0.5882353 , 0.37647063, 0.43921572],\n",
       "          ...,\n",
       "          [0.7176471 , 0.5647059 , 0.63529414],\n",
       "          [0.7294118 , 0.5686275 , 0.6392157 ],\n",
       "          [0.7176471 , 0.5568628 , 0.627451  ]],\n",
       " \n",
       "         [[0.5647059 , 0.32156864, 0.3803922 ],\n",
       "          [0.59607846, 0.38431376, 0.43921572],\n",
       "          [0.62352943, 0.40000004, 0.45882356],\n",
       "          ...,\n",
       "          [0.72156864, 0.5568628 , 0.63529414],\n",
       "          [0.72156864, 0.5529412 , 0.627451  ],\n",
       "          [0.7058824 , 0.5372549 , 0.6039216 ]],\n",
       " \n",
       "         [[0.54509807, 0.3019608 , 0.3529412 ],\n",
       "          [0.5921569 , 0.38823533, 0.43921572],\n",
       "          [0.6313726 , 0.41960788, 0.47450984],\n",
       "          ...,\n",
       "          [0.7176471 , 0.5568628 , 0.627451  ],\n",
       "          [0.7176471 , 0.54901963, 0.6156863 ],\n",
       "          [0.7019608 , 0.5372549 , 0.5921569 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.654902  , 0.48235297, 0.54901963],\n",
       "          [0.65882355, 0.4901961 , 0.5686275 ],\n",
       "          [0.6666667 , 0.5058824 , 0.5764706 ],\n",
       "          ...,\n",
       "          [0.7411765 , 0.58431375, 0.61960787],\n",
       "          [0.75294125, 0.5921569 , 0.64705884],\n",
       "          [0.7372549 , 0.5882353 , 0.64705884]],\n",
       " \n",
       "         [[0.64705884, 0.4784314 , 0.5568628 ],\n",
       "          [0.67058825, 0.5058824 , 0.58431375],\n",
       "          [0.6666667 , 0.5137255 , 0.5882353 ],\n",
       "          ...,\n",
       "          [0.73333335, 0.5647059 , 0.6313726 ],\n",
       "          [0.74509805, 0.5803922 , 0.63529414],\n",
       "          [0.74509805, 0.5882353 , 0.6313726 ]],\n",
       " \n",
       "         [[0.654902  , 0.4784314 , 0.5568628 ],\n",
       "          [0.6666667 , 0.5137255 , 0.5882353 ],\n",
       "          [0.68235296, 0.5294118 , 0.6039216 ],\n",
       "          ...,\n",
       "          [0.7411765 , 0.58431375, 0.61960787],\n",
       "          [0.7372549 , 0.5803922 , 0.6117647 ],\n",
       "          [0.7490196 , 0.58431375, 0.6313726 ]]],\n",
       " \n",
       " \n",
       "        [[[0.15294118, 0.12941177, 0.13725491],\n",
       "          [0.16078432, 0.11764707, 0.13333334],\n",
       "          [0.16862746, 0.1254902 , 0.14901961],\n",
       "          ...,\n",
       "          [0.16078432, 0.13725491, 0.15294118],\n",
       "          [0.16078432, 0.12156864, 0.15294118],\n",
       "          [0.15686275, 0.1137255 , 0.12941177]],\n",
       " \n",
       "         [[0.16470589, 0.12156864, 0.13725491],\n",
       "          [0.16862746, 0.1254902 , 0.14117648],\n",
       "          [0.16470589, 0.12941177, 0.14117648],\n",
       "          ...,\n",
       "          [0.16470589, 0.1254902 , 0.16078432],\n",
       "          [0.16078432, 0.1254902 , 0.14509805],\n",
       "          [0.16470589, 0.12941177, 0.14901961]],\n",
       " \n",
       "         [[0.16470589, 0.12156864, 0.13725491],\n",
       "          [0.16862746, 0.1254902 , 0.14117648],\n",
       "          [0.16470589, 0.14117648, 0.15686275],\n",
       "          ...,\n",
       "          [0.16862746, 0.13333334, 0.14509805],\n",
       "          [0.16862746, 0.13333334, 0.15294118],\n",
       "          [0.16470589, 0.12941177, 0.14901961]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.03529412, 0.03529412, 0.03529412],\n",
       "          [0.04705883, 0.04705883, 0.04705883],\n",
       "          [0.0509804 , 0.04313726, 0.04705883],\n",
       "          ...,\n",
       "          [0.0509804 , 0.04705883, 0.07843138],\n",
       "          [0.04705883, 0.03529412, 0.0627451 ],\n",
       "          [0.03137255, 0.02745098, 0.04705883]],\n",
       " \n",
       "         [[0.02745098, 0.02745098, 0.03529412],\n",
       "          [0.03529412, 0.03137255, 0.0509804 ],\n",
       "          [0.05490196, 0.04705883, 0.06666667],\n",
       "          ...,\n",
       "          [0.04313726, 0.03921569, 0.0627451 ],\n",
       "          [0.04313726, 0.04705883, 0.05490196],\n",
       "          [0.03137255, 0.03137255, 0.03921569]],\n",
       " \n",
       "         [[0.03921569, 0.01960784, 0.04313726],\n",
       "          [0.03137255, 0.02745098, 0.04705883],\n",
       "          [0.0509804 , 0.03137255, 0.05490196],\n",
       "          ...,\n",
       "          [0.04313726, 0.03921569, 0.05882353],\n",
       "          [0.03137255, 0.02745098, 0.04705883],\n",
       "          [0.02745098, 0.02352941, 0.04313726]]],\n",
       " \n",
       " \n",
       "        [[[0.86274517, 0.69411767, 0.627451  ],\n",
       "          [0.86666673, 0.7058824 , 0.63529414],\n",
       "          [0.86274517, 0.7019608 , 0.6313726 ],\n",
       "          ...,\n",
       "          [0.77647066, 0.59607846, 0.53333336],\n",
       "          [0.7607844 , 0.5803922 , 0.5176471 ],\n",
       "          [0.7568628 , 0.5647059 , 0.50980395]],\n",
       " \n",
       "         [[0.8705883 , 0.7019608 , 0.63529414],\n",
       "          [0.86274517, 0.7019608 , 0.6313726 ],\n",
       "          [0.83921576, 0.6784314 , 0.60784316],\n",
       "          ...,\n",
       "          [0.7411765 , 0.57254905, 0.49803925],\n",
       "          [0.74509805, 0.5686275 , 0.49411768],\n",
       "          [0.74509805, 0.5529412 , 0.48627454]],\n",
       " \n",
       "         [[0.8705883 , 0.70980394, 0.6392157 ],\n",
       "          [0.85098046, 0.6901961 , 0.61960787],\n",
       "          [0.8313726 , 0.67058825, 0.6       ],\n",
       "          ...,\n",
       "          [0.7490196 , 0.5803922 , 0.5058824 ],\n",
       "          [0.7490196 , 0.5647059 , 0.48627454],\n",
       "          [0.75294125, 0.5647059 , 0.48627454]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.7725491 , 0.58431375, 0.49803925],\n",
       "          [0.79215693, 0.62352943, 0.54901963],\n",
       "          [0.7960785 , 0.63529414, 0.5647059 ],\n",
       "          ...,\n",
       "          [0.61960787, 0.4431373 , 0.2901961 ],\n",
       "          [0.627451  , 0.427451  , 0.30588236],\n",
       "          [0.6627451 , 0.48627454, 0.37254903]],\n",
       " \n",
       "         [[0.7607844 , 0.5803922 , 0.45098042],\n",
       "          [0.76470596, 0.6039216 , 0.53333336],\n",
       "          [0.80392164, 0.63529414, 0.56078434],\n",
       "          ...,\n",
       "          [0.6313726 , 0.4431373 , 0.3019608 ],\n",
       "          [0.6313726 , 0.43529415, 0.30588236],\n",
       "          [0.654902  , 0.4784314 , 0.3647059 ]],\n",
       " \n",
       "         [[0.77647066, 0.59607846, 0.4666667 ],\n",
       "          [0.76470596, 0.6       , 0.5137255 ],\n",
       "          [0.79215693, 0.62352943, 0.54901963],\n",
       "          ...,\n",
       "          [0.6313726 , 0.43137258, 0.30980393],\n",
       "          [0.64705884, 0.454902  , 0.3372549 ],\n",
       "          [0.654902  , 0.4784314 , 0.35686275]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0.58431375, 0.38431376, 0.41960788],\n",
       "          [0.57254905, 0.36862746, 0.41960788],\n",
       "          [0.56078434, 0.34901962, 0.4039216 ],\n",
       "          ...,\n",
       "          [0.6509804 , 0.4784314 , 0.48235297],\n",
       "          [0.6431373 , 0.4901961 , 0.47058827],\n",
       "          [0.64705884, 0.47450984, 0.47058827]],\n",
       " \n",
       "         [[0.6039216 , 0.40784317, 0.45098042],\n",
       "          [0.5921569 , 0.38823533, 0.43921572],\n",
       "          [0.58431375, 0.3803922 , 0.43137258],\n",
       "          ...,\n",
       "          [0.64705884, 0.45882356, 0.45098042],\n",
       "          [0.627451  , 0.45098042, 0.43137258],\n",
       "          [0.34901962, 0.25882354, 0.29803923]],\n",
       " \n",
       "         [[0.60784316, 0.42352945, 0.46274513],\n",
       "          [0.6039216 , 0.42352945, 0.4666667 ],\n",
       "          [0.6       , 0.41176474, 0.45882356],\n",
       "          ...,\n",
       "          [0.6117647 , 0.454902  , 0.40784317],\n",
       "          [0.58431375, 0.427451  , 0.47058827],\n",
       "          [0.02352941, 0.01568628, 0.01960784]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.69803923, 0.54901963, 0.54509807],\n",
       "          [0.6784314 , 0.52156866, 0.5254902 ],\n",
       "          [0.69803923, 0.5411765 , 0.54509807],\n",
       "          ...,\n",
       "          [0.6784314 , 0.52156866, 0.52156866],\n",
       "          [0.6784314 , 0.5294118 , 0.5254902 ],\n",
       "          [0.6784314 , 0.5294118 , 0.5254902 ]],\n",
       " \n",
       "         [[0.6901961 , 0.53333336, 0.53333336],\n",
       "          [0.67058825, 0.50980395, 0.5254902 ],\n",
       "          [0.67058825, 0.5137255 , 0.5176471 ],\n",
       "          ...,\n",
       "          [0.67058825, 0.5137255 , 0.5058824 ],\n",
       "          [0.6745098 , 0.5254902 , 0.52156866],\n",
       "          [0.6784314 , 0.5294118 , 0.5254902 ]],\n",
       " \n",
       "         [[0.6784314 , 0.52156866, 0.5137255 ],\n",
       "          [0.64705884, 0.48627454, 0.5019608 ],\n",
       "          [0.6784314 , 0.52156866, 0.5254902 ],\n",
       "          ...,\n",
       "          [0.6509804 , 0.4901961 , 0.48235297],\n",
       "          [0.654902  , 0.5058824 , 0.49411768],\n",
       "          [0.6666667 , 0.50980395, 0.50980395]]],\n",
       " \n",
       " \n",
       "        [[[0.15686275, 0.05490196, 0.10588236],\n",
       "          [0.18431373, 0.05882353, 0.11764707],\n",
       "          [0.19607845, 0.0627451 , 0.12941177],\n",
       "          ...,\n",
       "          [0.09019608, 0.04313726, 0.09019608],\n",
       "          [0.09019608, 0.02352941, 0.08627451],\n",
       "          [0.05490196, 0.01568628, 0.05882353]],\n",
       " \n",
       "         [[0.16078432, 0.0509804 , 0.10980393],\n",
       "          [0.19607845, 0.0627451 , 0.12941177],\n",
       "          [0.20392159, 0.07450981, 0.14901961],\n",
       "          ...,\n",
       "          [0.1137255 , 0.0509804 , 0.09411766],\n",
       "          [0.10196079, 0.03529412, 0.09803922],\n",
       "          [0.07058824, 0.02745098, 0.08235294]],\n",
       " \n",
       "         [[0.18039216, 0.05882353, 0.12156864],\n",
       "          [0.21176472, 0.07843138, 0.14117648],\n",
       "          [0.21568629, 0.08627451, 0.15294118],\n",
       "          ...,\n",
       "          [0.13725491, 0.0509804 , 0.10196079],\n",
       "          [0.12156864, 0.03921569, 0.09803922],\n",
       "          [0.07843138, 0.03137255, 0.08627451]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.26666668, 0.12941177, 0.24705884],\n",
       "          [0.3019608 , 0.14901961, 0.27058825],\n",
       "          [0.3372549 , 0.18431373, 0.30588236],\n",
       "          ...,\n",
       "          [0.12941177, 0.0509804 , 0.09803922],\n",
       "          [0.09803922, 0.04313726, 0.09411766],\n",
       "          [0.07843138, 0.03137255, 0.08627451]],\n",
       " \n",
       "         [[0.24705884, 0.1137255 , 0.21960786],\n",
       "          [0.28235295, 0.14117648, 0.2509804 ],\n",
       "          [0.30980393, 0.15294118, 0.28627452],\n",
       "          ...,\n",
       "          [0.12156864, 0.04313726, 0.08627451],\n",
       "          [0.08627451, 0.03921569, 0.08627451],\n",
       "          [0.07450981, 0.01960784, 0.07058824]],\n",
       " \n",
       "         [[0.227451  , 0.10980393, 0.21176472],\n",
       "          [0.2627451 , 0.1254902 , 0.24313727],\n",
       "          [0.28627452, 0.14901961, 0.26666668],\n",
       "          ...,\n",
       "          [0.09411766, 0.04313726, 0.08235294],\n",
       "          [0.09411766, 0.03137255, 0.08235294],\n",
       "          [0.06666667, 0.01960784, 0.05882353]]],\n",
       " \n",
       " \n",
       "        [[[0.6627451 , 0.45098042, 0.45098042],\n",
       "          [0.6666667 , 0.45882356, 0.4431373 ],\n",
       "          [0.67058825, 0.454902  , 0.4431373 ],\n",
       "          ...,\n",
       "          [0.6745098 , 0.44705886, 0.43137258],\n",
       "          [0.6784314 , 0.46274513, 0.4431373 ],\n",
       "          [0.6784314 , 0.47058827, 0.454902  ]],\n",
       " \n",
       "         [[0.6666667 , 0.454902  , 0.454902  ],\n",
       "          [0.6431373 , 0.43529415, 0.41960788],\n",
       "          [0.6509804 , 0.43529415, 0.42352945],\n",
       "          ...,\n",
       "          [0.6745098 , 0.4666667 , 0.4431373 ],\n",
       "          [0.6745098 , 0.4666667 , 0.4431373 ],\n",
       "          [0.6901961 , 0.48235297, 0.4666667 ]],\n",
       " \n",
       "         [[0.6627451 , 0.45098042, 0.45098042],\n",
       "          [0.654902  , 0.43529415, 0.43137258],\n",
       "          [0.6509804 , 0.42352945, 0.41960788],\n",
       "          ...,\n",
       "          [0.67058825, 0.4784314 , 0.45882356],\n",
       "          [0.68235296, 0.48235297, 0.4666667 ],\n",
       "          [0.68235296, 0.48235297, 0.4666667 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.7137255 , 0.5176471 , 0.5137255 ],\n",
       "          [0.7137255 , 0.5254902 , 0.50980395],\n",
       "          [0.7137255 , 0.5372549 , 0.5137255 ],\n",
       "          ...,\n",
       "          [0.73333335, 0.5294118 , 0.48627454],\n",
       "          [0.7372549 , 0.53333336, 0.4901961 ],\n",
       "          [0.7372549 , 0.5294118 , 0.5137255 ]],\n",
       " \n",
       "         [[0.7137255 , 0.5176471 , 0.52156866],\n",
       "          [0.7176471 , 0.5254902 , 0.50980395],\n",
       "          [0.7058824 , 0.5176471 , 0.5019608 ],\n",
       "          ...,\n",
       "          [0.73333335, 0.5294118 , 0.48627454],\n",
       "          [0.74509805, 0.5411765 , 0.49803925],\n",
       "          [0.7607844 , 0.5529412 , 0.5294118 ]],\n",
       " \n",
       "         [[0.7176471 , 0.5254902 , 0.5058824 ],\n",
       "          [0.7254902 , 0.5254902 , 0.5137255 ],\n",
       "          [0.7176471 , 0.5058824 , 0.49803925],\n",
       "          ...,\n",
       "          [0.7372549 , 0.5411765 , 0.49803925],\n",
       "          [0.7490196 , 0.54509807, 0.5019608 ],\n",
       "          [0.7490196 , 0.5529412 , 0.5254902 ]]]], dtype=float32),\n",
       " array([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9ca38",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be47b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificador_binario(input_shape=(224,224,3), lr=1e-3):\n",
    "    entrada = Input(shape=input_shape, name='entrada_imagen')\n",
    "\n",
    "    # Bloque 1\n",
    "    x = Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(entrada)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Bloque 2\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Bloque 3\n",
    "    x = Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Bloque 4 (extra para más capacidad)\n",
    "    x = Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "    # Global pooling en lugar de Flatten (reduce parámetros)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Capa densa\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    salida = Dense(4, activation='softmax', name='salida_clases')(x)\n",
    "\n",
    "    modelo = Model(inputs=entrada, outputs=salida, name='cnn_mejorada')\n",
    "    modelo.compile(optimizer=Adam(learning_rate=lr),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "    return modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dec7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Desactiva todas las GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50cf0ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 13:16:41.254867: I external/local_xla/xla/service/service.cc:163] XLA service 0x7f7268015530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-29 13:16:41.254886: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): Host, Default Version\n",
      "2025-11-29 13:16:41.356844: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1764418602.912822   77518 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-11-29 13:16:42.915768: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 2667125544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/267\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34:39\u001b[0m 8s/step - accuracy: 0.5000 - loss: 1.3797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 13:16:45.149660: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 2667125544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/267\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:59\u001b[0m 2s/step - accuracy: 0.4922 - loss: 1.6559 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 13:16:46.960018: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 2667125544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  3/267\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:03\u001b[0m 2s/step - accuracy: 0.5052 - loss: 1.7011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 13:16:48.816259: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 2667125544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  4/267\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:06\u001b[0m 2s/step - accuracy: 0.5098 - loss: 1.7823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 13:16:50.694231: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 2667125544 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 2s/step - accuracy: 0.4552 - loss: 1.2396 - val_accuracy: 0.6976 - val_loss: 1.0997\n",
      "Epoch 2/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 2s/step - accuracy: 0.4974 - loss: 1.1203 - val_accuracy: 0.3427 - val_loss: 1.5615\n",
      "Epoch 3/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 2s/step - accuracy: 0.5194 - loss: 1.0869 - val_accuracy: 0.6996 - val_loss: 0.7158\n",
      "Epoch 4/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 2s/step - accuracy: 0.5306 - loss: 1.0505 - val_accuracy: 0.6230 - val_loss: 0.8703\n",
      "Epoch 5/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 2s/step - accuracy: 0.5540 - loss: 1.0361 - val_accuracy: 0.3931 - val_loss: 1.2568\n",
      "Epoch 6/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 2s/step - accuracy: 0.5653 - loss: 1.0251 - val_accuracy: 0.6169 - val_loss: 0.9488\n",
      "Epoch 7/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 2s/step - accuracy: 0.5575 - loss: 1.0205 - val_accuracy: 0.4718 - val_loss: 1.1045\n",
      "Epoch 8/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 2s/step - accuracy: 0.5645 - loss: 1.0077 - val_accuracy: 0.6633 - val_loss: 0.7984\n",
      "Epoch 9/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 2s/step - accuracy: 0.5511 - loss: 1.0184 - val_accuracy: 0.5484 - val_loss: 1.0816\n",
      "Epoch 10/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 2s/step - accuracy: 0.5662 - loss: 1.0015 - val_accuracy: 0.6351 - val_loss: 0.8099\n",
      "Epoch 11/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 2s/step - accuracy: 0.5726 - loss: 1.0006 - val_accuracy: 0.5887 - val_loss: 1.0737\n",
      "Epoch 12/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 2s/step - accuracy: 0.5752 - loss: 0.9744 - val_accuracy: 0.3931 - val_loss: 1.3957\n",
      "Epoch 13/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 2s/step - accuracy: 0.5698 - loss: 0.9770 - val_accuracy: 0.4778 - val_loss: 1.2641\n",
      "Epoch 14/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 2s/step - accuracy: 0.5719 - loss: 0.9646 - val_accuracy: 0.6411 - val_loss: 1.0187\n",
      "Epoch 15/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 2s/step - accuracy: 0.5693 - loss: 0.9748 - val_accuracy: 0.7863 - val_loss: 1.1993\n",
      "Epoch 16/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 2s/step - accuracy: 0.5868 - loss: 0.9782 - val_accuracy: 0.7399 - val_loss: 0.7801\n",
      "Epoch 17/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 2s/step - accuracy: 0.5798 - loss: 0.9756 - val_accuracy: 0.5565 - val_loss: 1.0968\n",
      "Epoch 18/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 2s/step - accuracy: 0.5547 - loss: 1.0021 - val_accuracy: 0.6109 - val_loss: 0.9086\n",
      "Epoch 19/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m514s\u001b[0m 2s/step - accuracy: 0.5784 - loss: 0.9760 - val_accuracy: 0.2520 - val_loss: 1.7702\n",
      "Epoch 20/20\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 2s/step - accuracy: 0.5985 - loss: 0.9516 - val_accuracy: 0.6028 - val_loss: 0.8665\n"
     ]
    }
   ],
   "source": [
    "# Ajustar nivel de logging de TensorFlow\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "modelo = clasificador_binario()  \n",
    "\n",
    "history = modelo.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b793dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n",
    "\n",
    "# Carpeta donde guardar\n",
    "save_dir = \"../models/classifier\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "modelo.save(f\"../models/full/full_model_{timestamp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea9826a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_mejorada\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cnn_mejorada\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ entrada_imagen (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ salida_clases (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ entrada_imagen (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ salida_clases (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,269,326</span> (4.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,269,326\u001b[0m (4.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,788</span> (1.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m422,788\u001b[0m (1.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">845,578</span> (3.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m845,578\u001b[0m (3.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
