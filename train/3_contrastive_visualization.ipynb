{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13692377,"sourceType":"datasetVersion","datasetId":8656484}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport json\nimport pandas as pd\nimport plotly.express as px\nimport datetime\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, InceptionV3, ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Add, ReLU, Lambda\nfrom tensorflow.keras.models import Model\n\nAUTOTUNE = tf.data.AUTOTUNE\nIMG_SIZE = (128, 128)\nEMBED_DIM = 128\nBATCH_SIZE = 100\nEPOCHS = 150\nTEMPERATURE = 0.05\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:23:22.643929Z","iopub.execute_input":"2025-11-20T10:23:22.644477Z","iopub.status.idle":"2025-11-20T10:23:22.650143Z","shell.execute_reply.started":"2025-11-20T10:23:22.644453Z","shell.execute_reply":"2025-11-20T10:23:22.649436Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def contar_archivos_en_carpetas(directorio):\n    # Recorre todas las carpetas dentro del directorio\n    for carpeta in os.listdir(directorio):\n        ruta_carpeta = os.path.join(directorio, carpeta)\n        if os.path.isdir(ruta_carpeta):\n            # Cuenta solo archivos (no subcarpetas)\n            archivos = [f for f in os.listdir(ruta_carpeta) \n                        if os.path.isfile(os.path.join(ruta_carpeta, f))]\n            print(f\"Carpeta: {carpeta} -> {len(archivos)} archivos\")\n\n# Ejemplo de uso\ndirectorio_base = \"/kaggle/input/hampreprocessed/malignas_classes/train\"  # Cambia esto por tu ruta\ncontar_archivos_en_carpetas(directorio_base)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:32:11.192628Z","iopub.execute_input":"2025-11-20T09:32:11.193315Z","iopub.status.idle":"2025-11-20T09:32:16.493117Z","shell.execute_reply.started":"2025-11-20T09:32:11.193291Z","shell.execute_reply":"2025-11-20T09:32:16.492382Z"}},"outputs":[{"name":"stdout","text":"Carpeta: mel -> 1002 archivos\nCarpeta: akiec -> 296 archivos\nCarpeta: bcc -> 461 archivos\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def contar_archivos_por_clase(directorio_base):\n    clases_totales = {}  # acumulador por clase\n\n    for conjunto in [\"train\", \"test\"]:\n        ruta_conjunto = os.path.join(directorio_base, conjunto)\n        if not os.path.exists(ruta_conjunto):\n            print(f\"No existe la carpeta: {ruta_conjunto}\")\n            continue\n\n        print(f\"\\nConjunto: {conjunto}\")\n        for carpeta in os.listdir(ruta_conjunto):\n            ruta_carpeta = os.path.join(ruta_conjunto, carpeta)\n            if os.path.isdir(ruta_carpeta):\n                archivos = [f for f in os.listdir(ruta_carpeta) \n                            if os.path.isfile(os.path.join(ruta_carpeta, f))]\n                cantidad = len(archivos)\n                print(f\"  Carpeta: {carpeta} -> {cantidad} archivos\")\n\n                # acumular por clase\n                if carpeta not in clases_totales:\n                    clases_totales[carpeta] = 0\n                clases_totales[carpeta] += cantidad\n\n    # Mostrar suma total por clase\n    print(\"\\nSuma total por clase (train + test):\")\n    for clase, total in clases_totales.items():\n        print(f\"  {clase} -> {total} archivos\")\n\n# Ejemplo de uso\ndirectorio_base = \"/kaggle/input/hampreprocessed/processed\"  # Ruta base que contiene train y test\ncontar_archivos_por_clase(directorio_base)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:32:16.493993Z","iopub.execute_input":"2025-11-20T09:32:16.494347Z","iopub.status.idle":"2025-11-20T09:32:47.378155Z","shell.execute_reply.started":"2025-11-20T09:32:16.494320Z","shell.execute_reply":"2025-11-20T09:32:47.377301Z"}},"outputs":[{"name":"stdout","text":"\nConjunto: train\n  Carpeta: benignas -> 7254 archivos\n  Carpeta: malignas -> 1759 archivos\n\nConjunto: test\n  Carpeta: benignas -> 807 archivos\n  Carpeta: malignas -> 195 archivos\n\nSuma total por clase (train + test):\n  benignas -> 8061 archivos\n  malignas -> 1954 archivos\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Importación de datos","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/hampreprocessed/malignas_classes/train\"\n\ndef get_generators(data_dir, preprocess_fn, target_size=IMG_SIZE, batch_size=BATCH_SIZE, validation_split=0.15):\n    datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_fn,\n        rotation_range=60,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.12,\n        brightness_range=[0.8, 1.2],\n        shear_range=0.2,\n        vertical_flip=True,\n        horizontal_flip=True,\n        validation_split=validation_split\n    )\n\n    train_generator = datagen.flow_from_directory(\n        data_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='training',\n        shuffle=True\n    )\n\n    val_generator = datagen.flow_from_directory(\n        data_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='validation',\n        shuffle=False\n    )\n\n    return train_generator, val_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:32:47.379724Z","iopub.execute_input":"2025-11-20T09:32:47.379999Z","iopub.status.idle":"2025-11-20T09:32:47.385266Z","shell.execute_reply.started":"2025-11-20T09:32:47.379980Z","shell.execute_reply":"2025-11-20T09:32:47.384528Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_generator, val_generator = get_generators(data_dir, lambda x: x/255.)\nnum_classes = len(train_generator.class_indices)\nclass_names = list(train_generator.class_indices.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:32:47.386080Z","iopub.execute_input":"2025-11-20T09:32:47.386330Z","iopub.status.idle":"2025-11-20T09:32:47.853767Z","shell.execute_reply.started":"2025-11-20T09:32:47.386307Z","shell.execute_reply":"2025-11-20T09:32:47.853214Z"}},"outputs":[{"name":"stdout","text":"Found 1496 images belonging to 3 classes.\nFound 263 images belonging to 3 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Modelo generador de embeddings","metadata":{}},{"cell_type":"code","source":"def contrastive_encoder(input_shape=(IMG_SIZE[0],IMG_SIZE[0],3), embedding_dim=EMBED_DIM):\n    inputs = Input(shape=input_shape)\n\n    # Bloque 1\n    x = Conv2D(64, 3, padding='same', use_bias=False)(inputs)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(64, 3, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    s = Conv2D(64, 1, padding='same', use_bias=False)(inputs)\n    s = BatchNormalization()(s)\n    x = Add()([x, s])\n    x = ReLU()(x)\n    x = MaxPooling2D()(x)\n\n    # Bloque 2\n    y = Conv2D(128, 3, padding='same', use_bias=False)(x)\n    y = BatchNormalization()(y)\n    y = ReLU()(y)\n    y = Conv2D(128, 3, padding='same', use_bias=False)(y)\n    y = BatchNormalization()(y)\n    s2 = Conv2D(128, 1, padding='same', use_bias=False)(x)\n    s2 = BatchNormalization()(s2)\n    y = Add()([y, s2])\n    y = ReLU()(y)\n    y = MaxPooling2D()(y)\n\n    # Bloque 3\n    z = Conv2D(256, 3, padding='same', use_bias=False)(y)\n    z = BatchNormalization()(z)\n    z = ReLU()(z)\n    z = Conv2D(256, 3, padding='same', use_bias=False)(z)\n    z = BatchNormalization()(z)\n    s3 = Conv2D(256, 1, padding='same', use_bias=False)(y)\n    s3 = BatchNormalization()(s3)\n    z = Add()([z, s3])\n    z = ReLU()(z)\n\n    z = GlobalAveragePooling2D()(z)\n    z = Dense(512, activation='relu')(z)\n    z = BatchNormalization()(z)\n\n    # Proyección (cabeza contrastiva)timestamps\n    p = Dense(EMBED_DIM, activation='relu')(z)\n    p = Dense(EMBED_DIM)(p)\n    outputs = Lambda(lambda t: tf.math.l2_normalize(t, axis=1), name=\"proj_norm\")(p)\n\n    return Model(inputs, outputs, name=\"ContrastiveEncoder\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:32:47.854519Z","iopub.execute_input":"2025-11-20T09:32:47.854806Z","iopub.status.idle":"2025-11-20T09:32:47.863418Z","shell.execute_reply.started":"2025-11-20T09:32:47.854757Z","shell.execute_reply":"2025-11-20T09:32:47.862688Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class SupConLoss(tf.keras.losses.Loss):\n    def __init__(self, temperature=0.1, name=\"supcon\"):\n        super().__init__(name=name)\n        self.temperature = temperature\n\n    def call(self, y_true, features):\n        \"\"\"\n        SupConLoss implementation.\n        Args:\n            y_true: [batch] integer class labels (not one-hot).\n            features: [batch, dim] embeddings.\n        \"\"\"\n        # Normalize embeddings\n        features = tf.math.l2_normalize(features, axis=1)\n        batch_size = tf.shape(features)[0]\n\n        # Similarity matrix\n        sim = tf.matmul(features, features, transpose_b=True)  # [B, B]\n        sim = sim / self.temperature\n\n        # Ensure labels are integers, not one-hot\n        if y_true.shape.ndims > 1 and y_true.shape[-1] > 1:\n            y_true = tf.argmax(y_true, axis=-1)\n\n        labels = tf.reshape(y_true, [-1, 1])  # [B, 1]\n        mask = tf.equal(labels, tf.transpose(labels))  # [B, B]\n        mask = tf.cast(mask, tf.float32)\n\n        # Remove self-contrast\n        eye = tf.eye(batch_size, dtype=tf.float32)\n        logits_mask = tf.ones_like(mask) - eye\n        mask = mask * logits_mask\n\n        # Log-softmax denominator excluding self\n        sim_max = tf.reduce_max(sim, axis=1, keepdims=True)\n        sim = sim - sim_max\n        exp_sim = tf.exp(sim) * logits_mask\n        denom = tf.reduce_sum(exp_sim, axis=1, keepdims=True) + 1e-9\n        log_prob = sim - tf.math.log(denom)\n\n        # Average log-prob of positives per anchor\n        pos_count = tf.reduce_sum(mask, axis=1) + 1e-9\n        mean_log_pos = tf.reduce_sum(mask * log_prob, axis=1) / pos_count\n\n        loss = -tf.reduce_mean(mean_log_pos)\n        return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:32:47.864100Z","iopub.execute_input":"2025-11-20T09:32:47.864403Z","iopub.status.idle":"2025-11-20T09:32:47.881006Z","shell.execute_reply.started":"2025-11-20T09:32:47.864385Z","shell.execute_reply":"2025-11-20T09:32:47.880300Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Entrenar representaciones","metadata":{}},{"cell_type":"code","source":"def evaluate_embeddings(model, generator, k=3, steps=50):\n    \"\"\"Evalúa embeddings con linear probe o k-NN.\"\"\"\n    all_embeds, all_labels = [], []\n    for _ in range(steps):\n        images, labels = next(generator)\n        embeds = model(images, training=False).numpy()\n        all_embeds.append(embeds)\n        all_labels.append(labels)\n    X = np.concatenate(all_embeds, axis=0)\n    y = np.concatenate(all_labels, axis=0)\n\n    # k-NN\n    clf = KNeighborsClassifier(n_neighbors=k)\n    clf.fit(X, y)\n    y_pred = clf.predict(X)\n    acc = accuracy_score(y, y_pred)\n    return acc\n\ndef train_supcon(model, train_generator, val_generator, loss_fn, optimizer, epochs=50):\n    steps_per_epoch = train_generator.samples // train_generator.batch_size\n    validation_steps = val_generator.samples // val_generator.batch_size\n\n    train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n    val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n\n    for epoch in range(epochs):\n        train_loss.reset_state()\n        val_loss.reset_state()\n\n        # Entrenamiento\n        for _ in range(steps_per_epoch):\n            images, labels = next(train_generator)\n            with tf.GradientTape() as tape:\n                embeddings = model(images, training=True)\n                loss = loss_fn(labels, embeddings)\n            grads = tape.gradient(loss, model.trainable_variables)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            train_loss.update_state(loss)\n\n        # Validación\n        for _ in range(validation_steps):\n            images, labels = next(val_generator)\n            embeddings = model(images, training=False)\n            loss = loss_fn(labels, embeddings)\n            val_loss.update_state(loss)\n\n        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss.result():.4f} - Val Loss: {val_loss.result():.4f}\")\n\n        # Evaluación cada 5 epochs\n        if (epoch + 1) % 5 == 0:\n            acc_knn = evaluate_embeddings(model, val_generator, k=3, steps=validation_steps)\n            print(f\"k-NN Acc: {acc_knn:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:32:47.881647Z","iopub.execute_input":"2025-11-20T09:32:47.881888Z","iopub.status.idle":"2025-11-20T09:32:47.899295Z","shell.execute_reply.started":"2025-11-20T09:32:47.881870Z","shell.execute_reply":"2025-11-20T09:32:47.898649Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"encoder = contrastive_encoder(embedding_dim=EMBED_DIM)\nencoder.trainable = True\nloss_fn = SupConLoss(temperature=TEMPERATURE)\noptimizer = Adam(learning_rate=8e-4)\ntrain_supcon(encoder, train_generator, val_generator, loss_fn, optimizer, epochs=60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:33:08.226616Z","iopub.execute_input":"2025-11-20T09:33:08.226963Z","iopub.status.idle":"2025-11-20T09:56:39.447302Z","shell.execute_reply.started":"2025-11-20T09:33:08.226938Z","shell.execute_reply":"2025-11-20T09:56:39.446438Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1763631188.855392      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nI0000 00:00:1763631192.414032      48 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/60 - Train Loss: 6.4283 - Val Loss: 4.6105\nEpoch 2/60 - Train Loss: 4.6666 - Val Loss: 4.4532\nEpoch 3/60 - Train Loss: 4.6144 - Val Loss: 4.4671\nEpoch 4/60 - Train Loss: 4.6048 - Val Loss: 4.6262\nEpoch 5/60 - Train Loss: 4.6004 - Val Loss: 4.3693\nk-NN Acc: 0.9202\nEpoch 6/60 - Train Loss: 4.5983 - Val Loss: 4.5974\nEpoch 7/60 - Train Loss: 4.5969 - Val Loss: 4.3624\nEpoch 8/60 - Train Loss: 4.5970 - Val Loss: 4.3619\nEpoch 9/60 - Train Loss: 4.5965 - Val Loss: 4.5958\nEpoch 10/60 - Train Loss: 4.5952 - Val Loss: 4.3616\nk-NN Acc: 0.9264\nEpoch 11/60 - Train Loss: 4.5956 - Val Loss: 4.5957\nEpoch 12/60 - Train Loss: 4.5946 - Val Loss: 4.3618\nEpoch 13/60 - Train Loss: 4.5948 - Val Loss: 4.3618\nEpoch 14/60 - Train Loss: 4.5947 - Val Loss: 4.5960\nEpoch 15/60 - Train Loss: 4.5942 - Val Loss: 4.3619\nk-NN Acc: 0.9264\nEpoch 16/60 - Train Loss: 4.5958 - Val Loss: 4.5957\nEpoch 17/60 - Train Loss: 4.5937 - Val Loss: 4.3619\nEpoch 18/60 - Train Loss: 4.5941 - Val Loss: 4.3621\nEpoch 19/60 - Train Loss: 4.5942 - Val Loss: 4.5964\nEpoch 20/60 - Train Loss: 4.5930 - Val Loss: 4.3624\nk-NN Acc: 0.9202\nEpoch 21/60 - Train Loss: 4.5931 - Val Loss: 4.5967\nEpoch 22/60 - Train Loss: 4.5932 - Val Loss: 4.3626\nEpoch 23/60 - Train Loss: 4.5934 - Val Loss: 4.3629\nEpoch 24/60 - Train Loss: 4.5932 - Val Loss: 4.5975\nEpoch 25/60 - Train Loss: 4.5931 - Val Loss: 4.3630\nk-NN Acc: 0.9080\nEpoch 26/60 - Train Loss: 4.5926 - Val Loss: 4.5975\nEpoch 27/60 - Train Loss: 4.5927 - Val Loss: 4.3626\nEpoch 28/60 - Train Loss: 4.5926 - Val Loss: 4.3630\nEpoch 29/60 - Train Loss: 4.5929 - Val Loss: 4.5978\nEpoch 30/60 - Train Loss: 4.5920 - Val Loss: 4.3642\nk-NN Acc: 0.9202\nEpoch 31/60 - Train Loss: 4.5956 - Val Loss: 4.5983\nEpoch 32/60 - Train Loss: 4.5925 - Val Loss: 4.3644\nEpoch 33/60 - Train Loss: 4.5929 - Val Loss: 4.3635\nEpoch 34/60 - Train Loss: 4.5924 - Val Loss: 4.5983\nEpoch 35/60 - Train Loss: 4.5927 - Val Loss: 4.3633\nk-NN Acc: 0.9325\nEpoch 36/60 - Train Loss: 4.5920 - Val Loss: 4.5976\nEpoch 37/60 - Train Loss: 4.5927 - Val Loss: 4.3636\nEpoch 38/60 - Train Loss: 4.5922 - Val Loss: 4.3628\nEpoch 39/60 - Train Loss: 4.5923 - Val Loss: 4.5973\nEpoch 40/60 - Train Loss: 4.5925 - Val Loss: 4.3636\nk-NN Acc: 0.9202\nEpoch 41/60 - Train Loss: 4.5919 - Val Loss: 4.5975\nEpoch 42/60 - Train Loss: 4.5929 - Val Loss: 4.3626\nEpoch 43/60 - Train Loss: 4.5923 - Val Loss: 4.3630\nEpoch 44/60 - Train Loss: 4.5920 - Val Loss: 4.5962\nEpoch 45/60 - Train Loss: 4.5923 - Val Loss: 4.3625\nk-NN Acc: 0.9202\nEpoch 46/60 - Train Loss: 4.5953 - Val Loss: 4.5965\nEpoch 47/60 - Train Loss: 4.5920 - Val Loss: 4.3625\nEpoch 48/60 - Train Loss: 4.5921 - Val Loss: 4.3626\nEpoch 49/60 - Train Loss: 4.5920 - Val Loss: 4.5967\nEpoch 50/60 - Train Loss: 4.5919 - Val Loss: 4.3625\nk-NN Acc: 0.9264\nEpoch 51/60 - Train Loss: 4.5922 - Val Loss: 4.5961\nEpoch 52/60 - Train Loss: 4.5907 - Val Loss: 4.3633\nEpoch 53/60 - Train Loss: 4.5919 - Val Loss: 4.3627\nEpoch 54/60 - Train Loss: 4.5923 - Val Loss: 4.5966\nEpoch 55/60 - Train Loss: 4.5919 - Val Loss: 4.3624\nk-NN Acc: 0.9202\nEpoch 56/60 - Train Loss: 4.5915 - Val Loss: 4.5967\nEpoch 57/60 - Train Loss: 4.5916 - Val Loss: 4.3631\nEpoch 58/60 - Train Loss: 4.5925 - Val Loss: 4.3619\nEpoch 59/60 - Train Loss: 4.5914 - Val Loss: 4.5962\nEpoch 60/60 - Train Loss: 4.5920 - Val Loss: 4.3628\nk-NN Acc: 0.9264\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Current timestamp\ntimestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n\nencoder.save(f\"encoder_{timestamp}.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:57:00.746717Z","iopub.execute_input":"2025-11-20T09:57:00.747368Z","iopub.status.idle":"2025-11-20T09:57:00.849804Z","shell.execute_reply.started":"2025-11-20T09:57:00.747343Z","shell.execute_reply":"2025-11-20T09:57:00.849225Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Calcular centroides de clases","metadata":{}},{"cell_type":"code","source":"def compute_centroids(encoder, generator):\n    \"\"\"\n    Calcula centroides de clase a partir de un generator de Keras.\n    Devuelve un dict {class_index: centroid_vector}.\n    \"\"\"\n    embeds, labels = [], []\n    for i in range(len(generator)):\n        x_batch, y_batch = generator[i]\n        e = encoder.predict(x_batch, verbose=0)\n        e = normalize(e)  # normalizar embeddings fila a fila\n        embeds.append(e)\n        labels.append(np.argmax(y_batch, axis=1))  # convertir one-hot a entero\n    # print(pd.Series(labels).value_counts())\n\n    embeds = np.concatenate(embeds)\n    labels = np.concatenate(labels)\n\n    centroids = {}\n    for c in np.unique(labels):\n        class_embeds = embeds[labels == c]\n        centroid = class_embeds.mean(axis=0)\n        centroid = centroid / np.linalg.norm(centroid)  # normalizar centroide\n        centroids[int(c)] = centroid.tolist()  # convertir a lista para JSON\n\n    return centroids\n\ndef save_centroids(centroids, filename=None):\n    if not filename:\n        timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n        filename = f\"centroids_{timestamp}.json\"\n    with open(filename, \"w\") as f:\n        json.dump(centroids, f)\n\ndef load_centroids(filename=\"centroids.json\"):\n    with open(filename, \"r\") as f:\n        centroids = json.load(f)\n    # convertir a numpy arrays\n    centroids = {int(k): np.array(v) for k, v in centroids.items()}\n    return centroids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:37:27.499678Z","iopub.execute_input":"2025-11-20T10:37:27.500265Z","iopub.status.idle":"2025-11-20T10:37:27.507483Z","shell.execute_reply.started":"2025-11-20T10:37:27.500238Z","shell.execute_reply":"2025-11-20T10:37:27.506588Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"centroids = compute_centroids(encoder, train_generator)\nsave_centroids(centroids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:37:27.658957Z","iopub.execute_input":"2025-11-20T10:37:27.659443Z","iopub.status.idle":"2025-11-20T10:37:44.592674Z","shell.execute_reply.started":"2025-11-20T10:37:27.659421Z","shell.execute_reply":"2025-11-20T10:37:44.592059Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"## Evaluar","metadata":{}},{"cell_type":"code","source":"def predict_class(encoder, x, centroids, probs=False):\n    \"\"\"\n    Predice la clase de una sola imagen x usando centroides.\n    \"\"\"\n    e = encoder.predict(np.expand_dims(x, axis=0), verbose=0)\n    e = normalize(e)  # normalizar embedding\n    sims = {c: np.dot(e, centroids[c]) for c in centroids}\n    if probs:\n        return sims\n    return max(sims, key=sims.get)  # clase con mayor similitud\n\ndef evaluate_accuracy(encoder, val_generator, centroids):\n    \"\"\"\n    Calcula el accuracy del val_generator usando centroides.\n    \"\"\"\n    y_true, y_pred = [], []\n\n    for i in range(len(val_generator)):\n        x_batch, y_batch = val_generator[i]\n        labels = np.argmax(y_batch, axis=1)  # convertir one-hot a enteros\n\n        for j in range(len(x_batch)):\n            pred = predict_class(encoder, x_batch[j], centroids)\n            y_true.append(labels[j])\n            y_pred.append(pred)\n\n    acc = accuracy_score(y_true, y_pred)\n    print(f\"Accuracy en val_generator: {acc:.4f}\")\n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:32:28.859482Z","iopub.execute_input":"2025-11-20T10:32:28.860078Z","iopub.status.idle":"2025-11-20T10:32:28.866435Z","shell.execute_reply.started":"2025-11-20T10:32:28.860053Z","shell.execute_reply":"2025-11-20T10:32:28.865808Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"evaluate_accuracy(encoder, train_generator, centroids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:32:29.972605Z","iopub.execute_input":"2025-11-20T10:32:29.972976Z","iopub.status.idle":"2025-11-20T10:34:23.960322Z","shell.execute_reply.started":"2025-11-20T10:32:29.972950Z","shell.execute_reply":"2025-11-20T10:34:23.959689Z"}},"outputs":[{"name":"stdout","text":"Accuracy en val_generator: 0.4398\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"0.43983957219251335"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"evaluate_embeddings(encoder, val_generator, k=3, steps=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:29:37.919977Z","iopub.execute_input":"2025-11-20T10:29:37.920719Z","iopub.status.idle":"2025-11-20T10:30:24.679953Z","shell.execute_reply.started":"2025-11-20T10:29:37.920697Z","shell.execute_reply":"2025-11-20T10:30:24.679135Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"0.9357126515671471"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## KNN as classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\ndef train_knn(encoder, train_generator, k=10):\n    \"\"\"\n    Entrena un KNN sobre los embeddings del train_generator.\n    Devuelve el clasificador entrenado.\n    \"\"\"\n    X, y = [], []\n    for i in range(len(train_generator)):\n        x_batch, y_batch = train_generator[i]\n        e = encoder.predict(x_batch, verbose=0)\n        e = e / np.linalg.norm(e, axis=1, keepdims=True)  # normalizar embeddings\n        X.append(e)\n        y.append(np.argmax(y_batch, axis=1))\n\n    X = np.concatenate(X)\n    y = np.concatenate(y)\n\n    knn = KNeighborsClassifier(n_neighbors=k, metric=\"cosine\")\n    knn.fit(X, y)\n    return knn\n\ndef evaluate_knn(encoder, val_generator, knn):\n    \"\"\"\n    Evalúa un KNN entrenado sobre el val_generator.\n    \"\"\"\n    X_val, y_val = [], []\n    for i in range(len(val_generator)):\n        x_batch, y_batch = val_generator[i]\n        e = encoder.predict(x_batch, verbose=0)\n        e = e / np.linalg.norm(e, axis=1, keepdims=True)\n        X_val.append(e)\n        y_val.append(np.argmax(y_batch, axis=1))\n\n    X_val = np.concatenate(X_val)\n    y_val = np.concatenate(y_val)\n\n    y_pred = knn.predict(X_val)\n    acc = accuracy_score(y_val, y_pred)\n    print(f\"Accuracy en val_generator con KNN: {acc:.4f}\")\n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:45:04.330051Z","iopub.execute_input":"2025-11-20T10:45:04.330641Z","iopub.status.idle":"2025-11-20T10:45:04.337737Z","shell.execute_reply.started":"2025-11-20T10:45:04.330611Z","shell.execute_reply":"2025-11-20T10:45:04.337091Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"knn = train_knn(encoder, train_generator)\nprint(\"Entrenado\")\nevaluate_knn(encoder, val_generator, knn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:45:05.368688Z","iopub.execute_input":"2025-11-20T10:45:05.369287Z","iopub.status.idle":"2025-11-20T10:45:25.296702Z","shell.execute_reply.started":"2025-11-20T10:45:05.369262Z","shell.execute_reply":"2025-11-20T10:45:25.295936Z"}},"outputs":[{"name":"stdout","text":"Entrenado\nAccuracy en val_generator con KNN: 0.4867\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"0.4866920152091255"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"# encoder.trainable = False\n# x = encoder.output\n# clf = Dense(num_classes, activation=\"softmax\")(x)\n# classifier = Model(encoder.input, clf)\n# classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:59:30.774260Z","iopub.execute_input":"2025-11-20T09:59:30.774518Z","iopub.status.idle":"2025-11-20T09:59:30.794684Z","shell.execute_reply.started":"2025-11-20T09:59:30.774498Z","shell.execute_reply":"2025-11-20T09:59:30.793919Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# labels = train_generator.classes\n# print(pd.Series(labels).value_counts())\n# print(num_classes)\n# class_weights = dict(enumerate(compute_class_weight(\n#     class_weight=\"balanced\",\n#     classes=np.unique(labels),\n#     y=labels\n# )))\n\n# classifier.fit(\n#     train_generator,\n#     validation_data=val_generator,\n#     epochs=100,\n#     class_weight=class_weights\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:17:52.226015Z","iopub.execute_input":"2025-11-20T10:17:52.230284Z","iopub.status.idle":"2025-11-20T10:17:52.233694Z","shell.execute_reply.started":"2025-11-20T10:17:52.230259Z","shell.execute_reply":"2025-11-20T10:17:52.233003Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# # Current timestamp\n# timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n\n# classifier.save(f\"classifier_{timestamp}.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T10:17:57.429325Z","iopub.execute_input":"2025-11-20T10:17:57.429916Z","iopub.status.idle":"2025-11-20T10:17:57.432968Z","shell.execute_reply.started":"2025-11-20T10:17:57.429890Z","shell.execute_reply":"2025-11-20T10:17:57.432188Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Evaluate KNN","metadata":{}},{"cell_type":"code","source":"def evaluate_knn(model, val_generator, class_names, k=5):\n    embs, labs = [], []\n    # recorrer todo el generador de validación\n    for imgs, labels in val_generator:\n        e = model(imgs, training=False).numpy()\n        embs.append(e)\n        # si labels es one-hot, convertir a entero con argmax\n        if labels.ndim > 1:\n            labs.append(np.argmax(labels, axis=1))\n        else:\n            labs.append(labels)\n\n    # concatenar embeddings y etiquetas\n    X = np.concatenate(embs, axis=0)\n    y = np.concatenate(labs, axis=0)\n\n    # entrenar y evaluar KNN\n    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n    knn.fit(X, y)\n    y_pred = knn.predict(X)\n\n    print(classification_report(y, y_pred, target_names=class_names))\n    print(confusion_matrix(y, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:56:39.469494Z","iopub.status.idle":"2025-11-20T09:56:39.470376Z","shell.execute_reply.started":"2025-11-20T09:56:39.470175Z","shell.execute_reply":"2025-11-20T09:56:39.470192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_knn(encoder, val_generator, class_names, k=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:56:39.471487Z","iopub.status.idle":"2025-11-20T09:56:39.471988Z","shell.execute_reply.started":"2025-11-20T09:56:39.471866Z","shell.execute_reply":"2025-11-20T09:56:39.471878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_embeddings_3d(model, val_ds, class_names, method=\"tsne\"):\n    # 1. Extraer embeddings y etiquetas\n    embs, labs = [], []\n    for imgs, labels in val_ds:\n        e = model(imgs, training=False).numpy()\n        embs.append(e)\n        labs.append(labels.numpy())\n    X = np.concatenate(embs, axis=0)\n    y = np.concatenate(labs, axis=0)\n\n    # 2. Reducir a 3D\n    if method == \"tsne\":\n        reducer = TSNE(n_components=3, perplexity=30, learning_rate=200, random_state=42)\n    else:\n        reducer = PCA(n_components=3)\n    X_reduced = reducer.fit_transform(X)\n\n    # 3. Visualizar con Plotly\n    fig = px.scatter_3d(\n        x=X_reduced[:,0], y=X_reduced[:,1], z=X_reduced[:,2],\n        color=[class_names[i] for i in y],\n        title=f\"Embeddings en 3D ({method.upper()})\",\n        opacity=0.7\n    )\n    fig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:56:39.472932Z","iopub.status.idle":"2025-11-20T09:56:39.473338Z","shell.execute_reply.started":"2025-11-20T09:56:39.473170Z","shell.execute_reply":"2025-11-20T09:56:39.473186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_embeddings_3d(encoder, val_generator, class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T09:56:39.474235Z","iopub.status.idle":"2025-11-20T09:56:39.474666Z","shell.execute_reply.started":"2025-11-20T09:56:39.474466Z","shell.execute_reply":"2025-11-20T09:56:39.474485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}