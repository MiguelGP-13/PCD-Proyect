{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e54f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Add, ReLU, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "IMG_SIZE = (224, 224)\n",
    "EMBED_DIM = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150\n",
    "TEMPERATURE = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed8e26",
   "metadata": {},
   "source": [
    "## Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40075b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/malignas_classes/train\"\n",
    "\n",
    "def get_generators(data_dir, preprocess_fn, target_size=(224, 224), batch_size=128, validation_split=0.15):\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_fn,\n",
    "        rotation_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=validation_split\n",
    "    )\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f52bb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1606 images belonging to 4 classes.\n",
      "Found 280 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = get_generators(data_dir, lambda x: x/255.)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "class_names = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec53479",
   "metadata": {},
   "source": [
    "## Modelo generador de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a522ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_encoder(input_shape=(224, 224, 3), embedding_dim=128):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Bloque 1\n",
    "    x = Conv2D(64, 3, padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    s = Conv2D(64, 1, padding='same', use_bias=False)(inputs)\n",
    "    s = BatchNormalization()(s)\n",
    "    x = Add()([x, s])\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    # Bloque 2\n",
    "    y = Conv2D(128, 3, padding='same', use_bias=False)(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = ReLU()(y)\n",
    "    y = Conv2D(128, 3, padding='same', use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    s2 = Conv2D(128, 1, padding='same', use_bias=False)(x)\n",
    "    s2 = BatchNormalization()(s2)\n",
    "    y = Add()([y, s2])\n",
    "    y = ReLU()(y)\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    # Bloque 3\n",
    "    z = Conv2D(256, 3, padding='same', use_bias=False)(y)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = ReLU()(z)\n",
    "    z = Conv2D(256, 3, padding='same', use_bias=False)(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    s3 = Conv2D(256, 1, padding='same', use_bias=False)(y)\n",
    "    s3 = BatchNormalization()(s3)\n",
    "    z = Add()([z, s3])\n",
    "    z = ReLU()(z)\n",
    "\n",
    "    z = GlobalAveragePooling2D()(z)\n",
    "    z = Dense(512, activation='relu')(z)\n",
    "    z = BatchNormalization()(z)\n",
    "\n",
    "    # Proyección (cabeza contrastiva)\n",
    "    p = Dense(EMBED_DIM, activation='relu')(z)\n",
    "    p = Dense(EMBED_DIM)(p)\n",
    "    outputs = Lambda(lambda t: tf.math.l2_normalize(t, axis=1), name=\"proj_norm\")(p)\n",
    "\n",
    "    return Model(inputs, outputs, name=\"ContrastiveEncoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fdf5319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupConLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=0.1, name=\"supcon\"):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def call(self, y_true, features):\n",
    "        # features: [batch, dim]; y_true: [batch]\n",
    "        features = tf.math.l2_normalize(features, axis=1)\n",
    "        batch_size = tf.shape(features)[0]\n",
    "\n",
    "        sim = tf.matmul(features, features, transpose_b=True)  # [B, B]\n",
    "        sim = sim / self.temperature\n",
    "\n",
    "        labels = tf.reshape(y_true, [-1, 1])  # [B, 1]\n",
    "        mask = tf.equal(labels, tf.transpose(labels))  # [B, B]\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        # Remove self-contrast\n",
    "        logits_mask = tf.ones_like(mask) - tf.eye(batch_size)\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # Log-softmax denom con exclusión self\n",
    "        sim_max = tf.reduce_max(sim, axis=1, keepdims=True)\n",
    "        sim = sim - sim_max\n",
    "        exp_sim = tf.exp(sim) * logits_mask\n",
    "        denom = tf.reduce_sum(exp_sim, axis=1, keepdims=True) + 1e-9\n",
    "        log_prob = sim - tf.math.log(denom)\n",
    "\n",
    "        # Promedio de log-prob de positivos por ancla\n",
    "        pos_count = tf.reduce_sum(mask, axis=1) + 1e-9\n",
    "        mean_log_pos = tf.reduce_sum(mask * log_prob, axis=1) / pos_count\n",
    "\n",
    "        loss = -tf.reduce_mean(mean_log_pos)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfc8ba",
   "metadata": {},
   "source": [
    "## Entrenar representaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4ca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supcon(model, train_generator, val_generator, loss_fn, optimizer, epochs=50):\n",
    "    train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "    val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss.reset_state()\n",
    "        val_loss.reset_state()\n",
    "\n",
    "        # Entrenamiento\n",
    "        for images, labels in train_generator:\n",
    "            with tf.GradientTape() as tape:\n",
    "                embeddings = model(images, training=True)\n",
    "                loss = loss_fn(labels, embeddings)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            train_loss.update_state(loss)\n",
    "\n",
    "        # Validación\n",
    "        for images, labels in val_generator:\n",
    "            embeddings = model(images, training=False)\n",
    "            loss = loss_fn(labels, embeddings)\n",
    "            val_loss.update_state(loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss.result():.4f} - Val Loss: {val_loss.result():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da6bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alumno\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = contrastive_encoder(input_shape=(224,224,3), embedding_dim=EMBED_DIM)\n",
    "loss_fn = SupConLoss(temperature=TEMPERATURE)\n",
    "optimizer = Adam(learning_rate=8e-4)\n",
    "train_supcon(encoder, train_generator, val_generator, loss_fn, optimizer, epochs=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65af95",
   "metadata": {},
   "source": [
    "## Entrenar clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alumno\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m encoder = contrastive_encoder(input_shape=(\u001b[32m224\u001b[39m,\u001b[32m224\u001b[39m,\u001b[32m3\u001b[39m), embedding_dim=EMBED_DIM)\n\u001b[32m      2\u001b[39m x = encoder.output\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m clf = Dense(\u001b[43mnum_classes\u001b[49m, activation=\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m)(x)\n\u001b[32m      4\u001b[39m classifier = Model(encoder.input, clf)\n\u001b[32m      6\u001b[39m classifier.compile(optimizer=\u001b[33m\"\u001b[39m\u001b[33madam\u001b[39m\u001b[33m\"\u001b[39m, loss=\u001b[33m\"\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m, metrics=[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "x = encoder.output\n",
    "clf = Dense(num_classes, activation=\"softmax\")(x)\n",
    "classifier = Model(encoder.input, clf)\n",
    "classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f93885",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_generator.classes\n",
    "class_weights = dict(enumerate(compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")))\n",
    "\n",
    "classifier.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f83398",
   "metadata": {},
   "source": [
    "## Evaluate KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(model, val_generator, class_names, k=5):\n",
    "    embs, labs = [], []\n",
    "    # recorrer todo el generador de validación\n",
    "    for imgs, labels in val_generator:\n",
    "        e = model(imgs, training=False).numpy()\n",
    "        embs.append(e)\n",
    "        # si labels es one-hot, convertir a entero con argmax\n",
    "        if labels.ndim > 1:\n",
    "            labs.append(np.argmax(labels, axis=1))\n",
    "        else:\n",
    "            labs.append(labels)\n",
    "\n",
    "    # concatenar embeddings y etiquetas\n",
    "    X = np.concatenate(embs, axis=0)\n",
    "    y = np.concatenate(labs, axis=0)\n",
    "\n",
    "    # entrenar y evaluar KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "    knn.fit(X, y)\n",
    "    y_pred = knn.predict(X)\n",
    "\n",
    "    print(classification_report(y, y_pred, target_names=class_names))\n",
    "    print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45519d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/ruta/a/HAM10000\"  # carpetas por clase\n",
    "evaluate_knn(encoder, val_generator, class_names, k=7)  # reutiliza val_ds y class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37538d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_3d(model, val_ds, class_names, method=\"tsne\"):\n",
    "    # 1. Extraer embeddings y etiquetas\n",
    "    embs, labs = [], []\n",
    "    for imgs, labels in val_ds:\n",
    "        e = model(imgs, training=False).numpy()\n",
    "        embs.append(e)\n",
    "        labs.append(labels.numpy())\n",
    "    X = np.concatenate(embs, axis=0)\n",
    "    y = np.concatenate(labs, axis=0)\n",
    "\n",
    "    # 2. Reducir a 3D\n",
    "    if method == \"tsne\":\n",
    "        reducer = TSNE(n_components=3, perplexity=30, learning_rate=200, random_state=42)\n",
    "    else:\n",
    "        reducer = PCA(n_components=3)\n",
    "    X_reduced = reducer.fit_transform(X)\n",
    "\n",
    "    # 3. Visualizar con Plotly\n",
    "    fig = px.scatter_3d(\n",
    "        x=X_reduced[:,0], y=X_reduced[:,1], z=X_reduced[:,2],\n",
    "        color=[class_names[i] for i in y],\n",
    "        title=f\"Embeddings en 3D ({method.upper()})\",\n",
    "        opacity=0.7\n",
    "    )\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
