{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e54f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 19:40:49.679100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-18 19:40:51.010064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Add, ReLU, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "IMG_SIZE = (224, 224)\n",
    "EMBED_DIM = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150\n",
    "TEMPERATURE = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1c2ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta: bcc -> 461 archivos\n",
      "Carpeta: akiec -> 296 archivos\n",
      "Carpeta: mel -> 1002 archivos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def contar_archivos_en_carpetas(directorio):\n",
    "    # Recorre todas las carpetas dentro del directorio\n",
    "    for carpeta in os.listdir(directorio):\n",
    "        ruta_carpeta = os.path.join(directorio, carpeta)\n",
    "        if os.path.isdir(ruta_carpeta):\n",
    "            # Cuenta solo archivos (no subcarpetas)\n",
    "            archivos = [f for f in os.listdir(ruta_carpeta) \n",
    "                        if os.path.isfile(os.path.join(ruta_carpeta, f))]\n",
    "            print(f\"Carpeta: {carpeta} -> {len(archivos)} archivos\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "directorio_base = \"../data/malignas_classes/train\"  # Cambia esto por tu ruta\n",
    "contar_archivos_en_carpetas(directorio_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d79091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto: train\n",
      "  Carpeta: benignas -> 7254 archivos\n",
      "  Carpeta: malignas -> 1759 archivos\n",
      "\n",
      "Conjunto: test\n",
      "  Carpeta: benignas -> 807 archivos\n",
      "  Carpeta: malignas -> 195 archivos\n",
      "\n",
      "Suma total por clase (train + test):\n",
      "  benignas -> 8061 archivos\n",
      "  malignas -> 1954 archivos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def contar_archivos_por_clase(directorio_base):\n",
    "    clases_totales = {}  # acumulador por clase\n",
    "\n",
    "    for conjunto in [\"train\", \"test\"]:\n",
    "        ruta_conjunto = os.path.join(directorio_base, conjunto)\n",
    "        if not os.path.exists(ruta_conjunto):\n",
    "            print(f\"No existe la carpeta: {ruta_conjunto}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nConjunto: {conjunto}\")\n",
    "        for carpeta in os.listdir(ruta_conjunto):\n",
    "            ruta_carpeta = os.path.join(ruta_conjunto, carpeta)\n",
    "            if os.path.isdir(ruta_carpeta):\n",
    "                archivos = [f for f in os.listdir(ruta_carpeta) \n",
    "                            if os.path.isfile(os.path.join(ruta_carpeta, f))]\n",
    "                cantidad = len(archivos)\n",
    "                print(f\"  Carpeta: {carpeta} -> {cantidad} archivos\")\n",
    "\n",
    "                # acumular por clase\n",
    "                if carpeta not in clases_totales:\n",
    "                    clases_totales[carpeta] = 0\n",
    "                clases_totales[carpeta] += cantidad\n",
    "\n",
    "    # Mostrar suma total por clase\n",
    "    print(\"\\nSuma total por clase (train + test):\")\n",
    "    for clase, total in clases_totales.items():\n",
    "        print(f\"  {clase} -> {total} archivos\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "directorio_base = \"../data/processed\"  # Ruta base que contiene train y test\n",
    "contar_archivos_por_clase(directorio_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed8e26",
   "metadata": {},
   "source": [
    "## Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40075b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/malignas_classes/train\"\n",
    "\n",
    "def get_generators(data_dir, preprocess_fn, target_size=(224, 224), batch_size=128, validation_split=0.15):\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_fn,\n",
    "        rotation_range=60,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.12,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        shear_range=0.2,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=validation_split\n",
    "    )\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f52bb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1496 images belonging to 3 classes.\n",
      "Found 263 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = get_generators(data_dir, lambda x: x/255.)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "class_names = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec53479",
   "metadata": {},
   "source": [
    "## Modelo generador de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a522ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_encoder(input_shape=(224, 224, 3), embedding_dim=128):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Bloque 1\n",
    "    x = Conv2D(64, 3, padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    s = Conv2D(64, 1, padding='same', use_bias=False)(inputs)\n",
    "    s = BatchNormalization()(s)\n",
    "    x = Add()([x, s])\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    # Bloque 2\n",
    "    y = Conv2D(128, 3, padding='same', use_bias=False)(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = ReLU()(y)\n",
    "    y = Conv2D(128, 3, padding='same', use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    s2 = Conv2D(128, 1, padding='same', use_bias=False)(x)\n",
    "    s2 = BatchNormalization()(s2)\n",
    "    y = Add()([y, s2])\n",
    "    y = ReLU()(y)\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    # Bloque 3\n",
    "    z = Conv2D(256, 3, padding='same', use_bias=False)(y)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = ReLU()(z)\n",
    "    z = Conv2D(256, 3, padding='same', use_bias=False)(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    s3 = Conv2D(256, 1, padding='same', use_bias=False)(y)\n",
    "    s3 = BatchNormalization()(s3)\n",
    "    z = Add()([z, s3])\n",
    "    z = ReLU()(z)\n",
    "\n",
    "    z = GlobalAveragePooling2D()(z)\n",
    "    z = Dense(512, activation='relu')(z)\n",
    "    z = BatchNormalization()(z)\n",
    "\n",
    "    # Proyección (cabeza contrastiva)\n",
    "    p = Dense(EMBED_DIM, activation='relu')(z)\n",
    "    p = Dense(EMBED_DIM)(p)\n",
    "    outputs = Lambda(lambda t: tf.math.l2_normalize(t, axis=1), name=\"proj_norm\")(p)\n",
    "\n",
    "    return Model(inputs, outputs, name=\"ContrastiveEncoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fdf5319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupConLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=0.1, name=\"supcon\"):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def call(self, y_true, features):\n",
    "        # features: [batch, dim]; y_true: [batch]\n",
    "        features = tf.math.l2_normalize(features, axis=1)\n",
    "        batch_size = tf.shape(features)[0]\n",
    "\n",
    "        sim = tf.matmul(features, features, transpose_b=True)  # [B, B]\n",
    "        sim = sim / self.temperature\n",
    "\n",
    "        labels = tf.reshape(y_true, [-1, 1])  # [B, 1]\n",
    "        mask = tf.equal(labels, tf.transpose(labels))  # [B, B]\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        # Remove self-contrast\n",
    "        logits_mask = tf.ones_like(mask) - tf.eye(batch_size)\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # Log-softmax denom con exclusión self\n",
    "        sim_max = tf.reduce_max(sim, axis=1, keepdims=True)\n",
    "        sim = sim - sim_max\n",
    "        exp_sim = tf.exp(sim) * logits_mask\n",
    "        denom = tf.reduce_sum(exp_sim, axis=1, keepdims=True) + 1e-9\n",
    "        log_prob = sim - tf.math.log(denom)\n",
    "\n",
    "        # Promedio de log-prob de positivos por ancla\n",
    "        pos_count = tf.reduce_sum(mask, axis=1) + 1e-9\n",
    "        mean_log_pos = tf.reduce_sum(mask * log_prob, axis=1) / pos_count\n",
    "\n",
    "        loss = -tf.reduce_mean(mean_log_pos)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfc8ba",
   "metadata": {},
   "source": [
    "## Entrenar representaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4ca95b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def train_supcon(model, train_generator, val_generator, loss_fn, optimizer, epochs=50):\n",
    "    steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "    validation_steps = val_generator.samples // val_generator.batch_size\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "    val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss.reset_state()\n",
    "        val_loss.reset_state()\n",
    "\n",
    "        # Entrenamiento\n",
    "        for _ in range(steps_per_epoch):\n",
    "            images, labels = next(train_generator)\n",
    "            with tf.GradientTape() as tape:\n",
    "                embeddings = model(images, training=True)\n",
    "                loss = loss_fn(labels, embeddings)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            train_loss.update_state(loss)\n",
    "\n",
    "        # Validación\n",
    "        for _ in range(validation_steps):\n",
    "            images, labels = next(val_generator)\n",
    "            embeddings = model(images, training=False)\n",
    "            loss = loss_fn(labels, embeddings)\n",
    "            val_loss.update_state(loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss.result():.4f} - Val Loss: {val_loss.result():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83da6bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-18 19:40:53.346781: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "encoder = contrastive_encoder(input_shape=(224,224,3), embedding_dim=EMBED_DIM)\n",
    "loss_fn = SupConLoss(temperature=TEMPERATURE)\n",
    "optimizer = Adam(learning_rate=8e-4)\n",
    "train_supcon(encoder, train_generator, val_generator, loss_fn, optimizer, epochs=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65af95",
   "metadata": {},
   "source": [
    "## Entrenar clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alumno\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m encoder = contrastive_encoder(input_shape=(\u001b[32m224\u001b[39m,\u001b[32m224\u001b[39m,\u001b[32m3\u001b[39m), embedding_dim=EMBED_DIM)\n\u001b[32m      2\u001b[39m x = encoder.output\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m clf = Dense(\u001b[43mnum_classes\u001b[49m, activation=\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m)(x)\n\u001b[32m      4\u001b[39m classifier = Model(encoder.input, clf)\n\u001b[32m      6\u001b[39m classifier.compile(optimizer=\u001b[33m\"\u001b[39m\u001b[33madam\u001b[39m\u001b[33m\"\u001b[39m, loss=\u001b[33m\"\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m, metrics=[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "x = encoder.output\n",
    "clf = Dense(num_classes, activation=\"softmax\")(x)\n",
    "classifier = Model(encoder.input, clf)\n",
    "classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f93885",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_generator.classes\n",
    "class_weights = dict(enumerate(compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")))\n",
    "\n",
    "classifier.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=20,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f83398",
   "metadata": {},
   "source": [
    "## Evaluate KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(model, val_generator, class_names, k=5):\n",
    "    embs, labs = [], []\n",
    "    # recorrer todo el generador de validación\n",
    "    for imgs, labels in val_generator:\n",
    "        e = model(imgs, training=False).numpy()\n",
    "        embs.append(e)\n",
    "        # si labels es one-hot, convertir a entero con argmax\n",
    "        if labels.ndim > 1:\n",
    "            labs.append(np.argmax(labels, axis=1))\n",
    "        else:\n",
    "            labs.append(labels)\n",
    "\n",
    "    # concatenar embeddings y etiquetas\n",
    "    X = np.concatenate(embs, axis=0)\n",
    "    y = np.concatenate(labs, axis=0)\n",
    "\n",
    "    # entrenar y evaluar KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "    knn.fit(X, y)\n",
    "    y_pred = knn.predict(X)\n",
    "\n",
    "    print(classification_report(y, y_pred, target_names=class_names))\n",
    "    print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45519d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/ruta/a/HAM10000\"  # carpetas por clase\n",
    "evaluate_knn(encoder, val_generator, class_names, k=7)  # reutiliza val_ds y class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37538d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_3d(model, val_ds, class_names, method=\"tsne\"):\n",
    "    # 1. Extraer embeddings y etiquetas\n",
    "    embs, labs = [], []\n",
    "    for imgs, labels in val_ds:\n",
    "        e = model(imgs, training=False).numpy()\n",
    "        embs.append(e)\n",
    "        labs.append(labels.numpy())\n",
    "    X = np.concatenate(embs, axis=0)\n",
    "    y = np.concatenate(labs, axis=0)\n",
    "\n",
    "    # 2. Reducir a 3D\n",
    "    if method == \"tsne\":\n",
    "        reducer = TSNE(n_components=3, perplexity=30, learning_rate=200, random_state=42)\n",
    "    else:\n",
    "        reducer = PCA(n_components=3)\n",
    "    X_reduced = reducer.fit_transform(X)\n",
    "\n",
    "    # 3. Visualizar con Plotly\n",
    "    fig = px.scatter_3d(\n",
    "        x=X_reduced[:,0], y=X_reduced[:,1], z=X_reduced[:,2],\n",
    "        color=[class_names[i] for i in y],\n",
    "        title=f\"Embeddings en 3D ({method.upper()})\",\n",
    "        opacity=0.7\n",
    "    )\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
