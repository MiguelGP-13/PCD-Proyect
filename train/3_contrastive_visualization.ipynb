{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e54f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Add, ReLU, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "IMG_SIZE = (224, 224)\n",
    "EMBED_DIM = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150\n",
    "TEMPERATURE = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed8e26",
   "metadata": {},
   "source": [
    "## Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40075b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/processed/train\"\n",
    "\n",
    "def get_generators(data_dir, preprocess_fn, target_size=(224, 224), batch_size=128, validation_split=0.15):\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_fn,\n",
    "        rotation_range=0.2,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=validation_split\n",
    "    )\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f52bb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7662 images belonging to 2 classes.\n",
      "Found 1351 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = get_generators(data_dir, lambda x: x/255.)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "class_names = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec53479",
   "metadata": {},
   "source": [
    "## Modelo generador de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a522ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_encoder(input_shape=(224, 224, 3), embedding_dim=128):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Bloque 1\n",
    "    x = Conv2D(64, 3, padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    s = Conv2D(64, 1, padding='same', use_bias=False)(inputs)\n",
    "    s = BatchNormalization()(s)\n",
    "    x = Add()([x, s])\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    # Bloque 2\n",
    "    y = Conv2D(128, 3, padding='same', use_bias=False)(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = ReLU()(y)\n",
    "    y = Conv2D(128, 3, padding='same', use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    s2 = Conv2D(128, 1, padding='same', use_bias=False)(x)\n",
    "    s2 = BatchNormalization()(s2)\n",
    "    y = Add()([y, s2])\n",
    "    y = ReLU()(y)\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    # Bloque 3\n",
    "    z = Conv2D(256, 3, padding='same', use_bias=False)(y)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = ReLU()(z)\n",
    "    z = Conv2D(256, 3, padding='same', use_bias=False)(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    s3 = Conv2D(256, 1, padding='same', use_bias=False)(y)\n",
    "    s3 = BatchNormalization()(s3)\n",
    "    z = Add()([z, s3])\n",
    "    z = ReLU()(z)\n",
    "\n",
    "    z = GlobalAveragePooling2D()(z)\n",
    "    z = Dense(512, activation='relu')(z)\n",
    "    z = BatchNormalization()(z)\n",
    "\n",
    "    # Proyección (cabeza contrastiva)\n",
    "    p = Dense(EMBED_DIM, activation='relu')(z)\n",
    "    p = Dense(EMBED_DIM)(p)\n",
    "    outputs = Lambda(lambda t: tf.math.l2_normalize(t, axis=1), name=\"proj_norm\")(p)\n",
    "\n",
    "    return Model(inputs, outputs, name=\"ContrastiveEncoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fdf5319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupConLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=0.1, name=\"supcon\"):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def call(self, y_true, features):\n",
    "        # features: [batch, dim]; y_true: [batch]\n",
    "        features = tf.math.l2_normalize(features, axis=1)\n",
    "        batch_size = tf.shape(features)[0]\n",
    "\n",
    "        sim = tf.matmul(features, features, transpose_b=True)  # [B, B]\n",
    "        sim = sim / self.temperature\n",
    "\n",
    "        labels = tf.reshape(y_true, [-1, 1])  # [B, 1]\n",
    "        mask = tf.equal(labels, tf.transpose(labels))  # [B, B]\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        # Remove self-contrast\n",
    "        logits_mask = tf.ones_like(mask) - tf.eye(batch_size)\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # Log-softmax denom con exclusión self\n",
    "        sim_max = tf.reduce_max(sim, axis=1, keepdims=True)\n",
    "        sim = sim - sim_max\n",
    "        exp_sim = tf.exp(sim) * logits_mask\n",
    "        denom = tf.reduce_sum(exp_sim, axis=1, keepdims=True) + 1e-9\n",
    "        log_prob = sim - tf.math.log(denom)\n",
    "\n",
    "        # Promedio de log-prob de positivos por ancla\n",
    "        pos_count = tf.reduce_sum(mask, axis=1) + 1e-9\n",
    "        mean_log_pos = tf.reduce_sum(mask * log_prob, axis=1) / pos_count\n",
    "\n",
    "        loss = -tf.reduce_mean(mean_log_pos)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfc8ba",
   "metadata": {},
   "source": [
    "## Entrenar representaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc4ca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supcon(model, train_generator, val_generator, loss_fn, optimizer, epochs=50):\n",
    "    train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "    val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss.reset_state()\n",
    "        val_loss.reset_state()\n",
    "\n",
    "        # Entrenamiento\n",
    "        for images, labels in train_generator:\n",
    "            with tf.GradientTape() as tape:\n",
    "                embeddings = model(images, training=True)\n",
    "                loss = loss_fn(labels, embeddings)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            train_loss.update_state(loss)\n",
    "\n",
    "        # Validación\n",
    "        for images, labels in val_generator:\n",
    "            embeddings = model(images, training=False)\n",
    "            loss = loss_fn(labels, embeddings)\n",
    "            val_loss.update_state(loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss.result():.4f} - Val Loss: {val_loss.result():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83da6bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [256,256] vs. [128,128] [Op:Sub] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m loss_fn = SupConLoss(temperature=TEMPERATURE)\n\u001b[32m      3\u001b[39m optimizer = Adam(learning_rate=\u001b[32m8e-4\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrain_supcon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_supcon\u001b[39m\u001b[34m(model, train_generator, val_generator, loss_fn, optimizer, epochs)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     12\u001b[39m     embeddings = model(images, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     loss = \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m grads = tape.gradient(loss, model.trainable_variables)\n\u001b[32m     15\u001b[39m optimizer.apply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model.trainable_variables))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\losses\\loss.py:67\u001b[39m, in \u001b[36mLoss.__call__\u001b[39m\u001b[34m(self, y_true, y_pred, sample_weight)\u001b[39m\n\u001b[32m     60\u001b[39m y_pred = tree.map_structure(\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: ops.convert_to_tensor(x, dtype=\u001b[38;5;28mself\u001b[39m.dtype), y_pred\n\u001b[32m     62\u001b[39m )\n\u001b[32m     63\u001b[39m y_true = tree.map_structure(\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: ops.convert_to_tensor(x, dtype=\u001b[38;5;28mself\u001b[39m.dtype), y_true\n\u001b[32m     65\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m losses = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m out_mask = backend.get_keras_mask(losses)\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m in_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mSupConLoss.call\u001b[39m\u001b[34m(self, y_true, features)\u001b[39m\n\u001b[32m     16\u001b[39m mask = tf.cast(mask, tf.float32)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Remove self-contrast\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m logits_mask = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m mask = mask * logits_mask\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Log-softmax denom con exclusión self\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    155\u001b[39m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\framework\\ops.py:6027\u001b[39m, in \u001b[36mraise_from_not_ok_status\u001b[39m\u001b[34m(e, name)\u001b[39m\n\u001b[32m   6025\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_from_not_ok_status\u001b[39m(e, name) -> NoReturn:\n\u001b[32m   6026\u001b[39m   e.message += (\u001b[33m\"\u001b[39m\u001b[33m name: \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m6027\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m core._status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: {{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [256,256] vs. [128,128] [Op:Sub] name: "
     ]
    }
   ],
   "source": [
    "encoder = contrastive_encoder(input_shape=(224,224,3), embedding_dim=EMBED_DIM)\n",
    "loss_fn = SupConLoss(temperature=TEMPERATURE)\n",
    "optimizer = Adam(learning_rate=8e-4)\n",
    "train_supcon(encoder, train_generator, val_generator, loss_fn, optimizer, epochs=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65af95",
   "metadata": {},
   "source": [
    "## Entrenar clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alumno\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m encoder = contrastive_encoder(input_shape=(\u001b[32m224\u001b[39m,\u001b[32m224\u001b[39m,\u001b[32m3\u001b[39m), embedding_dim=EMBED_DIM)\n\u001b[32m      2\u001b[39m x = encoder.output\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m clf = Dense(\u001b[43mnum_classes\u001b[49m, activation=\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m)(x)\n\u001b[32m      4\u001b[39m classifier = Model(encoder.input, clf)\n\u001b[32m      6\u001b[39m classifier.compile(optimizer=\u001b[33m\"\u001b[39m\u001b[33madam\u001b[39m\u001b[33m\"\u001b[39m, loss=\u001b[33m\"\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m, metrics=[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "x = encoder.output\n",
    "clf = Dense(num_classes, activation=\"softmax\")(x)\n",
    "classifier = Model(encoder.input, clf)\n",
    "classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "classifier.fit(train_generator, validation_data=val_generator, epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f83398",
   "metadata": {},
   "source": [
    "## Evaluate KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad9dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(model, val_generator, class_names, k=5):\n",
    "    embs, labs = [], []\n",
    "    # recorrer todo el generador de validación\n",
    "    for imgs, labels in val_generator:\n",
    "        e = model(imgs, training=False).numpy()\n",
    "        embs.append(e)\n",
    "        # si labels es one-hot, convertir a entero con argmax\n",
    "        if labels.ndim > 1:\n",
    "            labs.append(np.argmax(labels, axis=1))\n",
    "        else:\n",
    "            labs.append(labels)\n",
    "\n",
    "    # concatenar embeddings y etiquetas\n",
    "    X = np.concatenate(embs, axis=0)\n",
    "    y = np.concatenate(labs, axis=0)\n",
    "\n",
    "    # entrenar y evaluar KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
    "    knn.fit(X, y)\n",
    "    y_pred = knn.predict(X)\n",
    "\n",
    "    print(classification_report(y, y_pred, target_names=class_names))\n",
    "    print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45519d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/ruta/a/HAM10000\"  # carpetas por clase\n",
    "evaluate_knn(encoder, val_generator, class_names, k=7)  # reutiliza val_ds y class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37538d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings_3d(model, val_ds, class_names, method=\"tsne\"):\n",
    "    # 1. Extraer embeddings y etiquetas\n",
    "    embs, labs = [], []\n",
    "    for imgs, labels in val_ds:\n",
    "        e = model(imgs, training=False).numpy()\n",
    "        embs.append(e)\n",
    "        labs.append(labels.numpy())\n",
    "    X = np.concatenate(embs, axis=0)\n",
    "    y = np.concatenate(labs, axis=0)\n",
    "\n",
    "    # 2. Reducir a 3D\n",
    "    if method == \"tsne\":\n",
    "        reducer = TSNE(n_components=3, perplexity=30, learning_rate=200, random_state=42)\n",
    "    else:\n",
    "        reducer = PCA(n_components=3)\n",
    "    X_reduced = reducer.fit_transform(X)\n",
    "\n",
    "    # 3. Visualizar con Plotly\n",
    "    fig = px.scatter_3d(\n",
    "        x=X_reduced[:,0], y=X_reduced[:,1], z=X_reduced[:,2],\n",
    "        color=[class_names[i] for i in y],\n",
    "        title=f\"Embeddings en 3D ({method.upper()})\",\n",
    "        opacity=0.7\n",
    "    )\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
