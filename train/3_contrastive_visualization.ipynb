{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13692377,"sourceType":"datasetVersion","datasetId":8656484}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"51e54f2c","cell_type":"code","source":"import os\nimport numpy as np\nimport plotly.express as px\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, InceptionV3, ResNet50\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Add, ReLU, Lambda\nfrom tensorflow.keras.models import Model\n\nAUTOTUNE = tf.data.AUTOTUNE\nIMG_SIZE = (128, 128)\nEMBED_DIM = 128\nBATCH_SIZE = 100\nEPOCHS = 150\nTEMPERATURE = 0.05\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:23.220142Z","iopub.execute_input":"2025-11-19T18:51:23.220369Z","iopub.status.idle":"2025-11-19T18:51:28.999044Z","shell.execute_reply.started":"2025-11-19T18:51:23.220345Z","shell.execute_reply":"2025-11-19T18:51:28.998106Z"}},"outputs":[{"name":"stderr","text":"2025-11-19 18:51:24.566674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763578284.589489    1018 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763578284.596399    1018 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"id":"8d1c2ca2","cell_type":"code","source":"import os\n\ndef contar_archivos_en_carpetas(directorio):\n    # Recorre todas las carpetas dentro del directorio\n    for carpeta in os.listdir(directorio):\n        ruta_carpeta = os.path.join(directorio, carpeta)\n        if os.path.isdir(ruta_carpeta):\n            # Cuenta solo archivos (no subcarpetas)\n            archivos = [f for f in os.listdir(ruta_carpeta) \n                        if os.path.isfile(os.path.join(ruta_carpeta, f))]\n            print(f\"Carpeta: {carpeta} -> {len(archivos)} archivos\")\n\n# Ejemplo de uso\ndirectorio_base = \"/kaggle/input/hampreprocessed/malignas_classes/train\"  # Cambia esto por tu ruta\ncontar_archivos_en_carpetas(directorio_base)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:29.001301Z","iopub.execute_input":"2025-11-19T18:51:29.001926Z","iopub.status.idle":"2025-11-19T18:51:29.026514Z","shell.execute_reply.started":"2025-11-19T18:51:29.001883Z","shell.execute_reply":"2025-11-19T18:51:29.025767Z"}},"outputs":[{"name":"stdout","text":"Carpeta: mel -> 1002 archivos\nCarpeta: akiec -> 296 archivos\nCarpeta: bcc -> 461 archivos\n","output_type":"stream"}],"execution_count":2},{"id":"7d79091e","cell_type":"code","source":"import os\n\ndef contar_archivos_por_clase(directorio_base):\n    clases_totales = {}  # acumulador por clase\n\n    for conjunto in [\"train\", \"test\"]:\n        ruta_conjunto = os.path.join(directorio_base, conjunto)\n        if not os.path.exists(ruta_conjunto):\n            print(f\"No existe la carpeta: {ruta_conjunto}\")\n            continue\n\n        print(f\"\\nConjunto: {conjunto}\")\n        for carpeta in os.listdir(ruta_conjunto):\n            ruta_carpeta = os.path.join(ruta_conjunto, carpeta)\n            if os.path.isdir(ruta_carpeta):\n                archivos = [f for f in os.listdir(ruta_carpeta) \n                            if os.path.isfile(os.path.join(ruta_carpeta, f))]\n                cantidad = len(archivos)\n                print(f\"  Carpeta: {carpeta} -> {cantidad} archivos\")\n\n                # acumular por clase\n                if carpeta not in clases_totales:\n                    clases_totales[carpeta] = 0\n                clases_totales[carpeta] += cantidad\n\n    # Mostrar suma total por clase\n    print(\"\\nSuma total por clase (train + test):\")\n    for clase, total in clases_totales.items():\n        print(f\"  {clase} -> {total} archivos\")\n\n# Ejemplo de uso\ndirectorio_base = \"/kaggle/input/hampreprocessed/processed\"  # Ruta base que contiene train y test\ncontar_archivos_por_clase(directorio_base)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:29.027308Z","iopub.execute_input":"2025-11-19T18:51:29.027557Z","iopub.status.idle":"2025-11-19T18:51:46.455831Z","shell.execute_reply.started":"2025-11-19T18:51:29.027535Z","shell.execute_reply":"2025-11-19T18:51:46.455040Z"}},"outputs":[{"name":"stdout","text":"\nConjunto: train\n  Carpeta: benignas -> 7254 archivos\n  Carpeta: malignas -> 1759 archivos\n\nConjunto: test\n  Carpeta: benignas -> 807 archivos\n  Carpeta: malignas -> 195 archivos\n\nSuma total por clase (train + test):\n  benignas -> 8061 archivos\n  malignas -> 1954 archivos\n","output_type":"stream"}],"execution_count":3},{"id":"d2ed8e26","cell_type":"markdown","source":"## Importaci贸n de datos","metadata":{}},{"id":"40075b94","cell_type":"code","source":"data_dir = \"/kaggle/input/hampreprocessed/malignas_classes/train\"\n\ndef get_generators(data_dir, preprocess_fn, target_size=IMG_SIZE, batch_size=BATCH_SIZE, validation_split=0.15):\n    datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_fn,\n        rotation_range=60,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.12,\n        brightness_range=[0.8, 1.2],\n        shear_range=0.2,\n        vertical_flip=True,\n        horizontal_flip=True,\n        validation_split=validation_split\n    )\n\n    train_generator = datagen.flow_from_directory(\n        data_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='training',\n        shuffle=True\n    )\n\n    val_generator = datagen.flow_from_directory(\n        data_dir,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='validation',\n        shuffle=False\n    )\n\n    return train_generator, val_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:46.456689Z","iopub.execute_input":"2025-11-19T18:51:46.457075Z","iopub.status.idle":"2025-11-19T18:51:46.462281Z","shell.execute_reply.started":"2025-11-19T18:51:46.457045Z","shell.execute_reply":"2025-11-19T18:51:46.461497Z"}},"outputs":[],"execution_count":4},{"id":"7f52bb07","cell_type":"code","source":"train_generator, val_generator = get_generators(data_dir, lambda x: x/255.)\nnum_classes = len(train_generator.class_indices)\nclass_names = list(train_generator.class_indices.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:46.462937Z","iopub.execute_input":"2025-11-19T18:51:46.463180Z","iopub.status.idle":"2025-11-19T18:51:46.630841Z","shell.execute_reply.started":"2025-11-19T18:51:46.463156Z","shell.execute_reply":"2025-11-19T18:51:46.630095Z"}},"outputs":[{"name":"stdout","text":"Found 1496 images belonging to 3 classes.\nFound 263 images belonging to 3 classes.\n","output_type":"stream"}],"execution_count":5},{"id":"6ec53479","cell_type":"markdown","source":"## Modelo generador de embeddings","metadata":{}},{"id":"a522ef2d","cell_type":"code","source":"def contrastive_encoder(input_shape=(IMG_SIZE[0],IMG_SIZE[0],3), embedding_dim=EMBED_DIM):\n    inputs = Input(shape=input_shape)\n\n    # Bloque 1\n    x = Conv2D(64, 3, padding='same', use_bias=False)(inputs)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    x = Conv2D(64, 3, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    s = Conv2D(64, 1, padding='same', use_bias=False)(inputs)\n    s = BatchNormalization()(s)\n    x = Add()([x, s])\n    x = ReLU()(x)\n    x = MaxPooling2D()(x)\n\n    # Bloque 2\n    y = Conv2D(128, 3, padding='same', use_bias=False)(x)\n    y = BatchNormalization()(y)\n    y = ReLU()(y)\n    y = Conv2D(128, 3, padding='same', use_bias=False)(y)\n    y = BatchNormalization()(y)\n    s2 = Conv2D(128, 1, padding='same', use_bias=False)(x)\n    s2 = BatchNormalization()(s2)\n    y = Add()([y, s2])\n    y = ReLU()(y)\n    y = MaxPooling2D()(y)\n\n    # Bloque 3\n    z = Conv2D(256, 3, padding='same', use_bias=False)(y)\n    z = BatchNormalization()(z)\n    z = ReLU()(z)\n    z = Conv2D(256, 3, padding='same', use_bias=False)(z)\n    z = BatchNormalization()(z)\n    s3 = Conv2D(256, 1, padding='same', use_bias=False)(y)\n    s3 = BatchNormalization()(s3)\n    z = Add()([z, s3])\n    z = ReLU()(z)\n\n    z = GlobalAveragePooling2D()(z)\n    z = Dense(512, activation='relu')(z)\n    z = BatchNormalization()(z)\n\n    # Proyecci贸n (cabeza contrastiva)\n    p = Dense(EMBED_DIM, activation='relu')(z)\n    p = Dense(EMBED_DIM)(p)\n    outputs = Lambda(lambda t: tf.math.l2_normalize(t, axis=1), name=\"proj_norm\")(p)\n\n    return Model(inputs, outputs, name=\"ContrastiveEncoder\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:46.631757Z","iopub.execute_input":"2025-11-19T18:51:46.632061Z","iopub.status.idle":"2025-11-19T18:51:46.642115Z","shell.execute_reply.started":"2025-11-19T18:51:46.632035Z","shell.execute_reply":"2025-11-19T18:51:46.641384Z"}},"outputs":[],"execution_count":6},{"id":"9fdf5319","cell_type":"code","source":"class SupConLoss(tf.keras.losses.Loss):\n    def __init__(self, temperature=0.1, name=\"supcon\"):\n        super().__init__(name=name)\n        self.temperature = temperature\n\n    def call(self, y_true, features):\n        \"\"\"\n        SupConLoss implementation.\n        Args:\n            y_true: [batch] integer class labels (not one-hot).\n            features: [batch, dim] embeddings.\n        \"\"\"\n        # Normalize embeddings\n        features = tf.math.l2_normalize(features, axis=1)\n        batch_size = tf.shape(features)[0]\n\n        # Similarity matrix\n        sim = tf.matmul(features, features, transpose_b=True)  # [B, B]\n        sim = sim / self.temperature\n\n        # Ensure labels are integers, not one-hot\n        if y_true.shape.ndims > 1 and y_true.shape[-1] > 1:\n            y_true = tf.argmax(y_true, axis=-1)\n\n        labels = tf.reshape(y_true, [-1, 1])  # [B, 1]\n        mask = tf.equal(labels, tf.transpose(labels))  # [B, B]\n        mask = tf.cast(mask, tf.float32)\n\n        # Remove self-contrast\n        eye = tf.eye(batch_size, dtype=tf.float32)\n        logits_mask = tf.ones_like(mask) - eye\n        mask = mask * logits_mask\n\n        # Log-softmax denominator excluding self\n        sim_max = tf.reduce_max(sim, axis=1, keepdims=True)\n        sim = sim - sim_max\n        exp_sim = tf.exp(sim) * logits_mask\n        denom = tf.reduce_sum(exp_sim, axis=1, keepdims=True) + 1e-9\n        log_prob = sim - tf.math.log(denom)\n\n        # Average log-prob of positives per anchor\n        pos_count = tf.reduce_sum(mask, axis=1) + 1e-9\n        mean_log_pos = tf.reduce_sum(mask * log_prob, axis=1) / pos_count\n\n        loss = -tf.reduce_mean(mean_log_pos)\n        return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:46.642784Z","iopub.execute_input":"2025-11-19T18:51:46.643006Z","iopub.status.idle":"2025-11-19T18:51:46.661871Z","shell.execute_reply.started":"2025-11-19T18:51:46.642983Z","shell.execute_reply":"2025-11-19T18:51:46.661278Z"}},"outputs":[],"execution_count":7},{"id":"65dfc8ba","cell_type":"markdown","source":"## Entrenar representaciones","metadata":{}},{"id":"cc4ca95b","cell_type":"code","source":"def train_supcon(model, train_generator, val_generator, loss_fn, optimizer, epochs=50):\n    steps_per_epoch = train_generator.samples // train_generator.batch_size\n    validation_steps = val_generator.samples // val_generator.batch_size\n\n    train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n    val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n\n    for epoch in range(epochs):\n        train_loss.reset_state()\n        val_loss.reset_state()\n\n        # Entrenamiento\n        for _ in range(steps_per_epoch):\n            images, labels = next(train_generator)\n            with tf.GradientTape() as tape:\n                embeddings = model(images, training=True)\n                loss = loss_fn(labels, embeddings)\n            grads = tape.gradient(loss, model.trainable_variables)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            train_loss.update_state(loss)\n\n        # Validaci贸n\n        for _ in range(validation_steps):\n            images, labels = next(val_generator)\n            embeddings = model(images, training=False)\n            loss = loss_fn(labels, embeddings)\n            val_loss.update_state(loss)\n\n        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss.result():.4f} - Val Loss: {val_loss.result():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:46.662675Z","iopub.execute_input":"2025-11-19T18:51:46.662919Z","iopub.status.idle":"2025-11-19T18:51:46.680433Z","shell.execute_reply.started":"2025-11-19T18:51:46.662875Z","shell.execute_reply":"2025-11-19T18:51:46.679706Z"}},"outputs":[],"execution_count":8},{"id":"83da6bb7","cell_type":"code","source":"encoder = contrastive_encoder(embedding_dim=EMBED_DIM)\nloss_fn = SupConLoss(temperature=TEMPERATURE)\noptimizer = Adam(learning_rate=8e-4)\ntrain_supcon(encoder, train_generator, val_generator, loss_fn, optimizer, epochs=120)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T18:51:46.681184Z","iopub.execute_input":"2025-11-19T18:51:46.681425Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1763578306.890464    1018 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nI0000 00:00:1763578308.958754    1018 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/120 - Train Loss: 6.2461 - Val Loss: 4.6079\n","output_type":"stream"}],"execution_count":null},{"id":"ca65af95","cell_type":"markdown","source":"## Entrenar clasificador","metadata":{}},{"id":"5138190b","cell_type":"code","source":"x = encoder.output\nclf = Dense(num_classes, activation=\"softmax\")(x)\nclassifier = Model(encoder.input, clf)\nclassifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"02f93885","cell_type":"code","source":"labels = train_generator.classes\nclass_weights = dict(enumerate(compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(labels),\n    y=labels\n)))\n\nclassifier.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=20,\n    class_weight=class_weights\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c9f83398","cell_type":"markdown","source":"## Evaluate KNN","metadata":{}},{"id":"d5ad9dbb","cell_type":"code","source":"def evaluate_knn(model, val_generator, class_names, k=5):\n    embs, labs = [], []\n    # recorrer todo el generador de validaci贸n\n    for imgs, labels in val_generator:\n        e = model(imgs, training=False).numpy()\n        embs.append(e)\n        # si labels es one-hot, convertir a entero con argmax\n        if labels.ndim > 1:\n            labs.append(np.argmax(labels, axis=1))\n        else:\n            labs.append(labels)\n\n    # concatenar embeddings y etiquetas\n    X = np.concatenate(embs, axis=0)\n    y = np.concatenate(labs, axis=0)\n\n    # entrenar y evaluar KNN\n    knn = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n    knn.fit(X, y)\n    y_pred = knn.predict(X)\n\n    print(classification_report(y, y_pred, target_names=class_names))\n    print(confusion_matrix(y, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"45519d31","cell_type":"code","source":"data_dir = \"/ruta/a/HAM10000\"  # carpetas por clase\nevaluate_knn(encoder, val_generator, class_names, k=7)  # reutiliza val_ds y class_names\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"37538d0f","cell_type":"code","source":"def visualize_embeddings_3d(model, val_ds, class_names, method=\"tsne\"):\n    # 1. Extraer embeddings y etiquetas\n    embs, labs = [], []\n    for imgs, labels in val_ds:\n        e = model(imgs, training=False).numpy()\n        embs.append(e)\n        labs.append(labels.numpy())\n    X = np.concatenate(embs, axis=0)\n    y = np.concatenate(labs, axis=0)\n\n    # 2. Reducir a 3D\n    if method == \"tsne\":\n        reducer = TSNE(n_components=3, perplexity=30, learning_rate=200, random_state=42)\n    else:\n        reducer = PCA(n_components=3)\n    X_reduced = reducer.fit_transform(X)\n\n    # 3. Visualizar con Plotly\n    fig = px.scatter_3d(\n        x=X_reduced[:,0], y=X_reduced[:,1], z=X_reduced[:,2],\n        color=[class_names[i] for i in y],\n        title=f\"Embeddings en 3D ({method.upper()})\",\n        opacity=0.7\n    )\n    fig.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}