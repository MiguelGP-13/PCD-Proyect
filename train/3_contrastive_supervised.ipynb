{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:32:13.418519Z",
     "iopub.status.busy": "2025-11-29T11:32:13.418244Z",
     "iopub.status.idle": "2025-11-29T11:32:34.209881Z",
     "shell.execute_reply": "2025-11-29T11:32:34.209275Z",
     "shell.execute_reply.started": "2025-11-29T11:32:13.418494Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 22:08:20.535085: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import datetime\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, Add, ReLU, Lambda\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "IMG_SIZE = (128, 128)\n",
    "EMBED_DIM = 128\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 150\n",
    "TEMPERATURE = 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:32:34.210968Z",
     "iopub.status.busy": "2025-11-29T11:32:34.210480Z",
     "iopub.status.idle": "2025-11-29T11:32:38.636218Z",
     "shell.execute_reply": "2025-11-29T11:32:38.635519Z",
     "shell.execute_reply.started": "2025-11-29T11:32:34.210949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta: mel -> 948 archivos\n",
      "Carpeta: akiec -> 281 archivos\n",
      "Carpeta: bcc -> 442 archivos\n"
     ]
    }
   ],
   "source": [
    "def contar_archivos_en_carpetas(directorio):\n",
    "    # Recorre todas las carpetas dentro del directorio\n",
    "    for carpeta in os.listdir(directorio):\n",
    "        ruta_carpeta = os.path.join(directorio, carpeta)\n",
    "        if os.path.isdir(ruta_carpeta):\n",
    "            # Cuenta solo archivos (no subcarpetas)\n",
    "            archivos = [f for f in os.listdir(ruta_carpeta) \n",
    "                        if os.path.isfile(os.path.join(ruta_carpeta, f))]\n",
    "            print(f\"Carpeta: {carpeta} -> {len(archivos)} archivos\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "directorio_base = \"/kaggle/input/hampreprocessed/malignas_classes/train\"  # Cambia esto por tu ruta\n",
    "contar_archivos_en_carpetas(directorio_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T13:50:13.920587Z",
     "iopub.status.busy": "2025-11-26T13:50:13.920006Z",
     "iopub.status.idle": "2025-11-26T13:50:13.986034Z",
     "shell.execute_reply": "2025-11-26T13:50:13.985453Z",
     "shell.execute_reply.started": "2025-11-26T13:50:13.920561Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conjunto: train\n",
      "  Carpeta: benignas -> 6855 archivos\n",
      "  Carpeta: malignas -> 1662 archivos\n",
      "\n",
      "Conjunto: test\n",
      "  Carpeta: benignas -> 807 archivos\n",
      "  Carpeta: malignas -> 195 archivos\n",
      "\n",
      "Suma total por clase (train + test):\n",
      "  benignas -> 7662 archivos\n",
      "  malignas -> 1857 archivos\n"
     ]
    }
   ],
   "source": [
    "def contar_archivos_por_clase(directorio_base):\n",
    "    clases_totales = {}  # acumulador por clase\n",
    "\n",
    "    for conjunto in [\"train\", \"test\"]:\n",
    "        ruta_conjunto = os.path.join(directorio_base, conjunto)\n",
    "        if not os.path.exists(ruta_conjunto):\n",
    "            print(f\"No existe la carpeta: {ruta_conjunto}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nConjunto: {conjunto}\")\n",
    "        for carpeta in os.listdir(ruta_conjunto):\n",
    "            ruta_carpeta = os.path.join(ruta_conjunto, carpeta)\n",
    "            if os.path.isdir(ruta_carpeta):\n",
    "                archivos = [f for f in os.listdir(ruta_carpeta) \n",
    "                            if os.path.isfile(os.path.join(ruta_carpeta, f))]\n",
    "                cantidad = len(archivos)\n",
    "                print(f\"  Carpeta: {carpeta} -> {cantidad} archivos\")\n",
    "\n",
    "                # acumular por clase\n",
    "                if carpeta not in clases_totales:\n",
    "                    clases_totales[carpeta] = 0\n",
    "                clases_totales[carpeta] += cantidad\n",
    "\n",
    "    # Mostrar suma total por clase\n",
    "    print(\"\\nSuma total por clase (train + test):\")\n",
    "    for clase, total in clases_totales.items():\n",
    "        print(f\"  {clase} -> {total} archivos\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "directorio_base = \"/kaggle/input/hampreprocessed/malignas_classes\"  # Ruta base que contiene train y test\n",
    "contar_archivos_por_clase(directorio_base)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:32:38.637779Z",
     "iopub.status.busy": "2025-11-29T11:32:38.637531Z",
     "iopub.status.idle": "2025-11-29T11:32:39.216243Z",
     "shell.execute_reply": "2025-11-29T11:32:39.215615Z",
     "shell.execute_reply.started": "2025-11-29T11:32:38.637757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1671 images belonging to 3 classes.\n",
      "Found 88 images belonging to 3 classes.\n",
      "2    54\n",
      "1    19\n",
      "0    15\n",
      "Name: count, dtype: int64\n",
      "2    948\n",
      "1    442\n",
      "0    281\n",
      "Name: count, dtype: int64\n",
      "{0: 1.9822064056939501, 1: 1.260180995475113, 2: 0.5875527426160337}\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/malignas_classes/train\"\n",
    "val_dir = \"../data/malignas_classes/val\"\n",
    "\n",
    "def get_generators(data_dir, val_dir, preprocess_fn, target_size=(224, 224), batch_size=256):\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_fn,\n",
    "        rotation_range=60,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        zoom_range=0.12,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        shear_range=0.2,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = ImageDataGenerator(preprocessing_function=preprocess_fn).flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator\n",
    "\n",
    "train_generator, val_generator = get_generators(data_dir, val_dir, lambda x: x)\n",
    "print(pd.Series(val_generator.classes).value_counts())\n",
    "print(pd.Series(train_generator.classes).value_counts())\n",
    "\n",
    "labels = train_generator.classes  \n",
    "\n",
    "# Calculamos los pesos\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")\n",
    "\n",
    "# Lo convertimos en diccionario para Keras\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:32:39.217155Z",
     "iopub.status.busy": "2025-11-29T11:32:39.216943Z",
     "iopub.status.idle": "2025-11-29T11:32:39.354395Z",
     "shell.execute_reply": "2025-11-29T11:32:39.353647Z",
     "shell.execute_reply.started": "2025-11-29T11:32:39.217138Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1671 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, val_generator = get_generators(data_dir, val_dir, lambda x: x/255., target_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "class_names = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo generador de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:32:39.355552Z",
     "iopub.status.busy": "2025-11-29T11:32:39.355219Z",
     "iopub.status.idle": "2025-11-29T11:32:39.361365Z",
     "shell.execute_reply": "2025-11-29T11:32:39.360750Z",
     "shell.execute_reply.started": "2025-11-29T11:32:39.355528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_transfer_model(base_model_fn, input_shape=(224,224,3), n_classes=1, dropout=0.2, trainable_layers=0):\n",
    "    base = base_model_fn(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "\n",
    "    # Congelamos todas las capas primero\n",
    "    base.trainable = False\n",
    "\n",
    "    # Si se especifican capas entrenables, las activamos desde el final\n",
    "    if trainable_layers > 0:\n",
    "        for layer in base.layers[-trainable_layers:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    output = Dense(n_classes, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:32:39.362327Z",
     "iopub.status.busy": "2025-11-29T11:32:39.362041Z",
     "iopub.status.idle": "2025-11-29T11:32:39.380008Z",
     "shell.execute_reply": "2025-11-29T11:32:39.379240Z",
     "shell.execute_reply.started": "2025-11-29T11:32:39.362310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def contrastive_encoder(input_shape=(IMG_SIZE[0],IMG_SIZE[1],3), embedding_dim=EMBED_DIM):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Bloque 1\n",
    "    x = Conv2D(64, 3, padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    s = Conv2D(64, 1, padding='same', use_bias=False)(inputs)\n",
    "    s = BatchNormalization()(s)\n",
    "    x = Add()([x, s])\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    # Bloque 2\n",
    "    y = Conv2D(128, 3, padding='same', use_bias=False)(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = ReLU()(y)\n",
    "    y = Conv2D(128, 3, padding='same', use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    s2 = Conv2D(128, 1, padding='same', use_bias=False)(x)\n",
    "    s2 = BatchNormalization()(s2)\n",
    "    y = Add()([y, s2])\n",
    "    y = ReLU()(y)\n",
    "    y = MaxPooling2D()(y)\n",
    "\n",
    "    # Bloque 3\n",
    "    z = Conv2D(256, 3, padding='same', use_bias=False)(y)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = ReLU()(z)\n",
    "    z = Conv2D(256, 3, padding='same', use_bias=False)(z)\n",
    "    z = BatchNormalization()(z)\n",
    "    s3 = Conv2D(256, 1, padding='same', use_bias=False)(y)\n",
    "    s3 = BatchNormalization()(s3)\n",
    "    z = Add()([z, s3])\n",
    "    z = ReLU()(z)\n",
    "\n",
    "    z = GlobalAveragePooling2D()(z)\n",
    "    z = Dense(512, activation='relu')(z)\n",
    "    z = BatchNormalization()(z)\n",
    "\n",
    "    # Proyección (cabeza contrastiva)timestamps\n",
    "    p = Dense(embedding_dim, activation='relu')(z)\n",
    "    p = Dense(embedding_dim)(p)\n",
    "    outputs = Lambda(\n",
    "    lambda t: tf.math.l2_normalize(t, axis=1),\n",
    "    name=\"proj_norm\",\n",
    "    output_shape=(embedding_dim,))(p)\n",
    "\n",
    "\n",
    "    return Model(inputs, outputs, name=\"ContrastiveEncoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:32:39.381292Z",
     "iopub.status.busy": "2025-11-29T11:32:39.381056Z",
     "iopub.status.idle": "2025-11-29T11:32:39.434576Z",
     "shell.execute_reply": "2025-11-29T11:32:39.433920Z",
     "shell.execute_reply.started": "2025-11-29T11:32:39.381275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SupConLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=0.1, name=\"supcon\"):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def call(self, y_true, features):\n",
    "        \"\"\"\n",
    "        SupConLoss implementation.\n",
    "        Args:\n",
    "            y_true: [batch] integer class labels (not one-hot).\n",
    "            features: [batch, dim] embeddings.\n",
    "        \"\"\"\n",
    "        # Normalize embeddings\n",
    "        features = tf.math.l2_normalize(features, axis=1)\n",
    "        batch_size = tf.shape(features)[0]\n",
    "\n",
    "        # Similarity matrix\n",
    "        sim = tf.matmul(features, features, transpose_b=True)  # [B, B]\n",
    "        sim = sim / self.temperature\n",
    "\n",
    "        # Ensure labels are integers, not one-hot\n",
    "        if y_true.shape.ndims > 1 and y_true.shape[-1] > 1:\n",
    "            y_true = tf.argmax(y_true, axis=-1)\n",
    "\n",
    "        labels = tf.reshape(y_true, [-1, 1])  # [B, 1]\n",
    "        mask = tf.equal(labels, tf.transpose(labels))  # [B, B]\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        # Remove self-contrast\n",
    "        eye = tf.eye(batch_size, dtype=tf.float32)\n",
    "        logits_mask = tf.ones_like(mask) - eye\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # Log-softmax denominator excluding self\n",
    "        sim_max = tf.reduce_max(sim, axis=1, keepdims=True)\n",
    "        sim = sim - sim_max\n",
    "        exp_sim = tf.exp(sim) * logits_mask\n",
    "        denom = tf.reduce_sum(exp_sim, axis=1, keepdims=True) + 1e-9\n",
    "        log_prob = sim - tf.math.log(denom)\n",
    "\n",
    "        # Average log-prob of positives per anchor\n",
    "        pos_count = tf.reduce_sum(mask, axis=1) + 1e-9\n",
    "        mean_log_pos = tf.reduce_sum(mask * log_prob, axis=1) / pos_count\n",
    "\n",
    "        loss = -tf.reduce_mean(mean_log_pos)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar representaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:32:39.438017Z",
     "iopub.status.busy": "2025-11-29T11:32:39.437432Z",
     "iopub.status.idle": "2025-11-29T11:32:39.463676Z",
     "shell.execute_reply": "2025-11-29T11:32:39.462814Z",
     "shell.execute_reply.started": "2025-11-29T11:32:39.437984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_embeddings(model, train_generator, val_generator, k=3, train_steps=50, val_steps=50):\n",
    "    \"\"\"Entrena KNN y NearestCentroid con embeddings de train y evalúa en val.\"\"\"\n",
    "    # --- Embeddings de train ---\n",
    "    train_embeds, train_labels = [], []\n",
    "    for _ in range(train_steps):\n",
    "        images, labels = next(train_generator)\n",
    "        embeds = model(images, training=False).numpy()\n",
    "        train_embeds.append(embeds)\n",
    "        train_labels.append(np.argmax(labels, axis=1))  # convertir one-hot a entero\n",
    "    X_train = np.concatenate(train_embeds, axis=0)\n",
    "    y_train = np.concatenate(train_labels, axis=0)\n",
    "\n",
    "    # --- Embeddings de val ---\n",
    "    val_embeds, val_labels = [], []\n",
    "    for _ in range(val_steps):\n",
    "        images, labels = next(val_generator)\n",
    "        embeds = model(images, training=False).numpy()\n",
    "        val_embeds.append(embeds)\n",
    "        val_labels.append(np.argmax(labels, axis=1))\n",
    "    X_val = np.concatenate(val_embeds, axis=0)\n",
    "    y_val = np.concatenate(val_labels, axis=0)\n",
    "\n",
    "    # --- KNN ---\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=\"cosine\", weights=\"distance\")\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_val)\n",
    "    acc_knn = accuracy_score(y_val, y_pred_knn)\n",
    "\n",
    "    # --- Nearest Centroid ---\n",
    "    centroid = NearestCentroid(metric=\"cosine\")\n",
    "    centroid.fit(X_train, y_train)\n",
    "    y_pred_centroid = centroid.predict(X_val)\n",
    "    acc_centroid = accuracy_score(y_val, y_pred_centroid)\n",
    "\n",
    "    print(f\"k-NN Acc: {acc_knn:.4f}\")\n",
    "    print(f\"Nearest Centroid Acc: {acc_centroid:.4f}\")\n",
    "\n",
    "    return acc_knn, acc_centroid\n",
    "\n",
    "\n",
    "def train_supcon(model, train_generator, val_generator, loss_fn, optimizer, epochs=50, accumulate_steps=2):\n",
    "    steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "    validation_steps = val_generator.samples // val_generator.batch_size\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "    val_loss = tf.keras.metrics.Mean(name=\"val_loss\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss.reset_state()\n",
    "        val_loss.reset_state()\n",
    "\n",
    "        # Training\n",
    "        accum_grads = [tf.zeros_like(var) for var in model.trainable_variables]\n",
    "        step_count = 0\n",
    "\n",
    "        for _ in range(steps_per_epoch):\n",
    "            images, labels = next(train_generator)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                embeddings = model(images, training=True)\n",
    "                loss = loss_fn(labels, embeddings)\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            accum_grads = [accum + grad for accum, grad in zip(accum_grads, grads)]\n",
    "            step_count += 1\n",
    "            train_loss.update_state(loss)\n",
    "\n",
    "            # Apply gradients every `accumulate_steps`\n",
    "            if step_count % accumulate_steps == 0:\n",
    "                mean_grads = [accum / accumulate_steps for accum in accum_grads]\n",
    "                optimizer.apply_gradients(zip(mean_grads, model.trainable_variables))\n",
    "                accum_grads = [tf.zeros_like(var) for var in model.trainable_variables]\n",
    "\n",
    "        # Validation\n",
    "        for _ in range(validation_steps):\n",
    "            images, labels = next(val_generator)\n",
    "            embeddings = model(images, training=False)\n",
    "            loss = loss_fn(labels, embeddings)\n",
    "            val_loss.update_state(loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss.result():.4f} - Val Loss: {val_loss.result():.4f}\")\n",
    "\n",
    "        # Evaluation every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            acc_knn, acc_centroid = evaluate_embeddings(\n",
    "                model, train_generator, val_generator,\n",
    "                k=3, train_steps=steps_per_epoch, val_steps=validation_steps\n",
    "            )\n",
    "            print(f\"k-NN Acc: {acc_knn:.4f}\")\n",
    "            print(f\"Nearest Centroid Acc: {acc_centroid:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:23:59.130967Z",
     "iopub.status.busy": "2025-11-26T14:23:59.130403Z",
     "iopub.status.idle": "2025-11-26T14:26:19.895934Z",
     "shell.execute_reply": "2025-11-26T14:26:19.895137Z",
     "shell.execute_reply.started": "2025-11-26T14:23:59.130940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 3.7674 - Val Loss: 4.2446\n",
      "Epoch 2/5 - Train Loss: 3.7599 - Val Loss: 3.3043\n",
      "Epoch 3/5 - Train Loss: 3.7808 - Val Loss: 3.8724\n",
      "Epoch 4/5 - Train Loss: 3.7725 - Val Loss: 3.3122\n",
      "Epoch 5/5 - Train Loss: 3.7239 - Val Loss: 4.0184\n",
      "k-NN Acc: 1.0000\n",
      "Nearest Centroid Acc: 1.0000\n",
      "k-NN Acc: 1.0000\n",
      "Nearest Centroid Acc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_nearest_centroid.py:179: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder = contrastive_encoder(embedding_dim=EMBED_DIM)\n",
    "encoder.trainable = True\n",
    "loss_fn = SupConLoss(temperature=TEMPERATURE)\n",
    "optimizer = Adam(learning_rate=8e-4)\n",
    "train_supcon(encoder, train_generator, val_generator, loss_fn, optimizer, epochs=5)\n",
    "# Current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n",
    "\n",
    "encoder.save(f\"encoder_{timestamp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:36:42.006976Z",
     "iopub.status.busy": "2025-11-29T11:36:42.006670Z",
     "iopub.status.idle": "2025-11-29T11:37:01.102505Z",
     "shell.execute_reply": "2025-11-29T11:37:01.101501Z",
     "shell.execute_reply.started": "2025-11-29T11:36:42.006956Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1671 images belonging to 3 classes.\n",
      "Found 88 images belonging to 3 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling Conv2D.call().\n\n\u001b[1m{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[256,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(256, 224, 224, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/1011283216.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSupConLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEMPERATURE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_supcon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Guardar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_47/459893304.py\u001b[0m in \u001b[0;36mtrain_supcon\u001b[0;34m(model, train_generator, val_generator, loss_fn, optimizer, epochs, accumulate_steps)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling Conv2D.call().\n\n\u001b[1m{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[256,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(256, 224, 224, 64), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "train_generator, val_generator = get_generators(data_dir,val_dir, vgg16_preprocess)\n",
    "vgg_encoder = create_transfer_model(VGG16, trainable_layers= 4)\n",
    "encoder.trainable = True\n",
    "loss_fn = SupConLoss(temperature=TEMPERATURE)\n",
    "optimizer = Adam(learning_rate=8e-4)\n",
    "train_supcon(vgg_encoder, train_generator, val_generator, loss_fn, optimizer, epochs=25)\n",
    "\n",
    "# Guardar\n",
    "timestamp = datetime.datetime.now().strftime(\"%m_%d_%H:%M\")\n",
    "vgg_encoder.save(os.path.join(save_dir, f\"vgg16_encoder_{timestamp}.keras\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular centroides de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:27:20.369434Z",
     "iopub.status.busy": "2025-11-26T14:27:20.368594Z",
     "iopub.status.idle": "2025-11-26T14:27:20.376819Z",
     "shell.execute_reply": "2025-11-26T14:27:20.375969Z",
     "shell.execute_reply.started": "2025-11-26T14:27:20.369408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_centroids(encoder, generator):\n",
    "    \"\"\"\n",
    "    Calcula centroides de clase a partir de un generator de Keras.\n",
    "    Devuelve un dict {class_index: centroid_vector}.\n",
    "    \"\"\"\n",
    "    embeds, labels = [], []\n",
    "    for i in range(len(generator)):\n",
    "        x_batch, y_batch = generator[i]\n",
    "        e = encoder.predict(x_batch, verbose=0)\n",
    "        e = normalize(e)  # normalizar embeddings fila a fila\n",
    "        embeds.append(e)\n",
    "        labels.append(np.argmax(y_batch, axis=1))  # convertir one-hot a entero\n",
    "    # print(pd.Series(labels).value_counts())\n",
    "\n",
    "    embeds = np.concatenate(embeds)\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    centroids = {}\n",
    "    for c in np.unique(labels):\n",
    "        class_embeds = embeds[labels == c]\n",
    "        centroid = class_embeds.mean(axis=0)\n",
    "        centroid = centroid / np.linalg.norm(centroid)  # normalizar centroide\n",
    "        centroids[int(c)] = centroid.tolist()  # convertir a lista para JSON\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def save_centroids(centroids, filename=None):\n",
    "    if not filename:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n",
    "        filename = f\"centroids_{timestamp}.json\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(centroids, f)\n",
    "\n",
    "def load_centroids(filename=\"centroids.json\"):\n",
    "    with open(filename, \"r\") as f:\n",
    "        centroids = json.load(f)\n",
    "    # convertir a numpy arrays\n",
    "    centroids = {int(k): np.array(v) for k, v in centroids.items()}\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:27:24.127264Z",
     "iopub.status.busy": "2025-11-26T14:27:24.126704Z",
     "iopub.status.idle": "2025-11-26T14:27:51.756972Z",
     "shell.execute_reply": "2025-11-26T14:27:51.756326Z",
     "shell.execute_reply.started": "2025-11-26T14:27:24.127241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764167245.090675     770 service.cc:148] XLA service 0x7b5600005d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764167245.091266     770 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1764167248.198486     770 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "centroids = compute_centroids(encoder, train_generator)\n",
    "save_centroids(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:27:51.758754Z",
     "iopub.status.busy": "2025-11-26T14:27:51.758178Z",
     "iopub.status.idle": "2025-11-26T14:27:51.764811Z",
     "shell.execute_reply": "2025-11-26T14:27:51.764120Z",
     "shell.execute_reply.started": "2025-11-26T14:27:51.758733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict_class(encoder, x, centroids, probs=False):\n",
    "    \"\"\"\n",
    "    Predice la clase de una sola imagen x usando centroides.\n",
    "    \"\"\"\n",
    "    e = encoder.predict(np.expand_dims(x, axis=0), verbose=0)\n",
    "    e = normalize(e)  # normalizar embedding\n",
    "    sims = {c: np.dot(e, centroids[c]) for c in centroids}\n",
    "    if probs:\n",
    "        return sims\n",
    "    return max(sims, key=sims.get)  # clase con mayor similitud\n",
    "\n",
    "def evaluate_accuracy(encoder, val_generator, centroids):\n",
    "    \"\"\"\n",
    "    Calcula el accuracy del val_generator usando centroides.\n",
    "    \"\"\"\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for i in range(len(val_generator)):\n",
    "        x_batch, y_batch = val_generator[i]\n",
    "        labels = np.argmax(y_batch, axis=1)  # convertir one-hot a enteros\n",
    "\n",
    "        for j in range(len(x_batch)):\n",
    "            pred = predict_class(encoder, x_batch[j], centroids)\n",
    "            y_true.append(labels[j])\n",
    "            y_pred.append(pred)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy en val_generator: {acc:.4f}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T14:27:51.765780Z",
     "iopub.status.busy": "2025-11-26T14:27:51.765450Z",
     "iopub.status.idle": "2025-11-26T14:29:51.769369Z",
     "shell.execute_reply": "2025-11-26T14:29:51.768582Z",
     "shell.execute_reply.started": "2025-11-26T14:27:51.765763Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en val_generator: 0.6373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6373429084380611"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(encoder, val_generator, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:33:22.815218Z",
     "iopub.status.busy": "2025-11-29T11:33:22.814929Z",
     "iopub.status.idle": "2025-11-29T11:33:22.822777Z",
     "shell.execute_reply": "2025-11-29T11:33:22.822096Z",
     "shell.execute_reply.started": "2025-11-29T11:33:22.815194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def train_knn(encoder, train_generator, k=10):\n",
    "    \"\"\"\n",
    "    Entrena un KNN sobre los embeddings del train_generator.\n",
    "    Devuelve el clasificador entrenado.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(train_generator)):\n",
    "        x_batch, y_batch = train_generator[i]\n",
    "        e = encoder.predict(x_batch, verbose=0)\n",
    "        e = e / np.linalg.norm(e, axis=1, keepdims=True)  # normalizar embeddings\n",
    "        X.append(e)\n",
    "        y.append(np.argmax(y_batch, axis=1))\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric=\"cosine\")\n",
    "    knn.fit(X, y)\n",
    "    return knn\n",
    "\n",
    "def evaluate_knn(encoder, val_generator, knn):\n",
    "    \"\"\"\n",
    "    Evalúa un KNN entrenado sobre el val_generator.\n",
    "    \"\"\"\n",
    "    X_val, y_val = [], []\n",
    "    for i in range(len(val_generator)):\n",
    "        x_batch, y_batch = val_generator[i]\n",
    "        e = encoder.predict(x_batch, verbose=0)\n",
    "        e = e / np.linalg.norm(e, axis=1, keepdims=True)\n",
    "        X_val.append(e)\n",
    "        y_val.append(np.argmax(y_batch, axis=1))\n",
    "\n",
    "    X_val = np.concatenate(X_val)\n",
    "    y_val = np.concatenate(y_val)\n",
    "\n",
    "    y_pred = knn.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Accuracy en val_generator con KNN: {acc:.4f}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:35:09.921917Z",
     "iopub.status.busy": "2025-11-29T11:35:09.921129Z",
     "iopub.status.idle": "2025-11-29T11:35:34.083036Z",
     "shell.execute_reply": "2025-11-29T11:35:34.082430Z",
     "shell.execute_reply.started": "2025-11-29T11:35:09.921891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenado\n",
      "Accuracy en val_generator con KNN: 0.7841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7840909090909091"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = contrastive_encoder(\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    embedding_dim=EMBED_DIM\n",
    ")\n",
    "\n",
    "# Cargar solo los pesos entrenados\n",
    "encoder.load_weights(\"/kaggle/working/encoder_finetuned_11_26_h15_34.keras\")\n",
    "\n",
    "knn = train_knn(encoder, train_generator)\n",
    "import pickle\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo\n",
    "timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n",
    "with open(f\"knn_model_{timestamp}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(knn, f)\n",
    "print(\"Entrenado\")\n",
    "evaluate_knn(encoder, val_generator, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T11:36:19.915757Z",
     "iopub.status.busy": "2025-11-29T11:36:19.915459Z",
     "iopub.status.idle": "2025-11-29T11:36:42.005064Z",
     "shell.execute_reply": "2025-11-29T11:36:42.004399Z",
     "shell.execute_reply.started": "2025-11-29T11:36:19.915730Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenado\n",
      "Accuracy en val_generator con KNN: 0.8295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8295454545454546"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = contrastive_encoder(\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    embedding_dim=EMBED_DIM\n",
    ")\n",
    "\n",
    "# Cargar solo los pesos entrenados\n",
    "encoder.load_weights(\"/kaggle/working/encoder_11_26_h14_27.keras\")\n",
    "knn = train_knn(encoder, train_generator, k=3)\n",
    "import pickle\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo\n",
    "timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n",
    "with open(f\"knn_model_{timestamp}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(knn, f)\n",
    "print(\"Entrenado\")\n",
    "evaluate_knn(encoder, val_generator, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:14:14.551271Z",
     "iopub.status.busy": "2025-11-26T15:14:14.550510Z",
     "iopub.status.idle": "2025-11-26T15:14:14.577047Z",
     "shell.execute_reply": "2025-11-26T15:14:14.576356Z",
     "shell.execute_reply.started": "2025-11-26T15:14:14.551244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoder.trainable = False\n",
    "x = encoder.output\n",
    "clf = Dense(num_classes, activation=\"softmax\")(x)\n",
    "classifier = Model(encoder.input, clf)\n",
    "classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:30:38.730228Z",
     "iopub.status.busy": "2025-11-26T15:30:38.729661Z",
     "iopub.status.idle": "2025-11-26T15:33:44.759443Z",
     "shell.execute_reply": "2025-11-26T15:33:44.758879Z",
     "shell.execute_reply.started": "2025-11-26T15:30:38.730208Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    948\n",
      "1    442\n",
      "0    281\n",
      "Name: count, dtype: int64\n",
      "3\n",
      "Epoch 1/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 756ms/step - accuracy: 0.8555 - loss: 0.3975 - val_accuracy: 0.8523 - val_loss: 0.3850\n",
      "Epoch 2/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 638ms/step - accuracy: 0.8616 - loss: 0.4258 - val_accuracy: 0.8523 - val_loss: 0.3888\n",
      "Epoch 3/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 637ms/step - accuracy: 0.8578 - loss: 0.4094 - val_accuracy: 0.8523 - val_loss: 0.3921\n",
      "Epoch 4/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 653ms/step - accuracy: 0.8530 - loss: 0.3950 - val_accuracy: 0.8295 - val_loss: 0.4187\n",
      "Epoch 5/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 651ms/step - accuracy: 0.8671 - loss: 0.4082 - val_accuracy: 0.8409 - val_loss: 0.3976\n",
      "Epoch 6/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 656ms/step - accuracy: 0.8726 - loss: 0.3902 - val_accuracy: 0.8409 - val_loss: 0.3950\n",
      "Epoch 7/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 628ms/step - accuracy: 0.8829 - loss: 0.3808 - val_accuracy: 0.8182 - val_loss: 0.4450\n",
      "Epoch 8/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 628ms/step - accuracy: 0.8878 - loss: 0.3756 - val_accuracy: 0.8182 - val_loss: 0.4339\n",
      "Epoch 9/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 639ms/step - accuracy: 0.8848 - loss: 0.3675 - val_accuracy: 0.8182 - val_loss: 0.4260\n",
      "Epoch 10/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 627ms/step - accuracy: 0.8828 - loss: 0.3632 - val_accuracy: 0.8182 - val_loss: 0.4345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7d23903d64d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_generator.classes\n",
    "print(pd.Series(labels).value_counts())\n",
    "print(num_classes)\n",
    "class_weights = dict(enumerate(compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(labels),\n",
    "    y=labels\n",
    ")))\n",
    "\n",
    "classifier.compile(optimizer=Adam(learning_rate=1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "encoder.trainable = True\n",
    "classifier.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:34:21.407763Z",
     "iopub.status.busy": "2025-11-26T15:34:21.407360Z",
     "iopub.status.idle": "2025-11-26T15:34:21.520531Z",
     "shell.execute_reply": "2025-11-26T15:34:21.519727Z",
     "shell.execute_reply.started": "2025-11-26T15:34:21.407739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n",
    "\n",
    "encoder.save(f\"encoder_finetuned_{timestamp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:34:29.648848Z",
     "iopub.status.busy": "2025-11-26T15:34:29.648156Z",
     "iopub.status.idle": "2025-11-26T15:34:29.835999Z",
     "shell.execute_reply": "2025-11-26T15:34:29.835418Z",
     "shell.execute_reply.started": "2025-11-26T15:34:29.648823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%m_%d_h%H_%M\")\n",
    "\n",
    "classifier.save(f\"classifier_{timestamp}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:39:09.137402Z",
     "iopub.status.busy": "2025-11-26T15:39:09.137123Z",
     "iopub.status.idle": "2025-11-26T15:39:09.143235Z",
     "shell.execute_reply": "2025-11-26T15:39:09.142665Z",
     "shell.execute_reply.started": "2025-11-26T15:39:09.137380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_embeddings_3d(model, val_generator, class_names, method=\"tsne\"):\n",
    "    # 1. Calcular cuántos pasos tiene la validación\n",
    "    validation_steps = val_generator.samples // val_generator.batch_size\n",
    "\n",
    "    embs, labs = [], []\n",
    "    for _ in range(validation_steps):\n",
    "        images, labels = next(val_generator)\n",
    "        e = model(images, training=False).numpy()\n",
    "        embs.append(e)\n",
    "        labs.append(labels)\n",
    "\n",
    "    X = np.concatenate(embs, axis=0)\n",
    "    y = np.concatenate(labs, axis=0)\n",
    "\n",
    "    # 2. Reducir a 3D\n",
    "    if method == \"tsne\":\n",
    "        reducer = TSNE(n_components=3, perplexity=30, learning_rate=200, random_state=42)\n",
    "    else:\n",
    "        reducer = PCA(n_components=3)\n",
    "    X_reduced = reducer.fit_transform(X)\n",
    "\n",
    "    # 3. Visualizar con Plotly\n",
    "    fig = px.scatter_3d(\n",
    "        x=X_reduced[:,0],\n",
    "        y=X_reduced[:,1],\n",
    "        z=X_reduced[:,2],\n",
    "        color=[class_names[i] for i in y],\n",
    "        title=f\"Embeddings en 3D ({method.upper()})\",\n",
    "        opacity=0.7\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = contrastive_encoder(input_shape=(128,128,3), embedding_dim=128)\n",
    "encoder.load_weights(\"../models/encoder/encoder_11_26_h14_27.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-26T15:39:01.704109Z",
     "iopub.status.idle": "2025-11-26T15:39:01.704539Z",
     "shell.execute_reply": "2025-11-26T15:39:01.704403Z",
     "shell.execute_reply.started": "2025-11-26T15:39:01.704387Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "perplexity must be less than n_samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvisualize_embeddings_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m, in \u001b[0;36mvisualize_embeddings_3d\u001b[0;34m(model, val_generator, class_names, method)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     reducer \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m X_reduced \u001b[38;5;241m=\u001b[39m \u001b[43mreducer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 3. Visualizar con Plotly\u001b[39;00m\n\u001b[1;32m     23\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mscatter_3d(\n\u001b[1;32m     24\u001b[0m     x\u001b[38;5;241m=\u001b[39mX_reduced[:,\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     25\u001b[0m     y\u001b[38;5;241m=\u001b[39mX_reduced[:,\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n",
      "File \u001b[0;32m~/python3.12/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/python3.12/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python3.12/lib/python3.12/site-packages/sklearn/manifold/_t_sne.py:1177\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/python3.12/lib/python3.12/site-packages/sklearn/manifold/_t_sne.py:862\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: perplexity must be less than n_samples"
     ]
    }
   ],
   "source": [
    "visualize_embeddings_3d(encoder, val_generator, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:39:16.727239Z",
     "iopub.status.busy": "2025-11-26T15:39:16.726972Z",
     "iopub.status.idle": "2025-11-26T15:39:16.732895Z",
     "shell.execute_reply": "2025-11-26T15:39:16.732103Z",
     "shell.execute_reply.started": "2025-11-26T15:39:16.727220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "\n",
    "def build_siamese_network(encoder, input_shape):\n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "\n",
    "    encoded_a = encoder(input_a)\n",
    "    encoded_b = encoder(input_b)\n",
    "\n",
    "    # Distancia euclídea entre embeddings\n",
    "    distance = Lambda(euclidean_distance)([encoded_a, encoded_b])\n",
    "\n",
    "    # Una neurona con sigmoide decide si son similares\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "    siamese_net = Model([input_a, input_b], outputs)\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:42:54.634607Z",
     "iopub.status.busy": "2025-11-26T15:42:54.634300Z",
     "iopub.status.idle": "2025-11-26T15:42:55.027606Z",
     "shell.execute_reply": "2025-11-26T15:42:55.026875Z",
     "shell.execute_reply.started": "2025-11-26T15:42:54.634583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ContrastiveEncoder  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,406,848</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ContrastiveEncod… │\n",
       "│                     │                   │            │ ContrastiveEncod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ContrastiveEncoder  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m1,406,848\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ ContrastiveEncod… │\n",
       "│                     │                   │            │ ContrastiveEncod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m2\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,406,850</span> (5.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,406,850\u001b[0m (5.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,403,138</span> (5.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,403,138\u001b[0m (5.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> (14.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,712\u001b[0m (14.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = contrastive_encoder(\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    embedding_dim=EMBED_DIM\n",
    ")\n",
    "\n",
    "# Cargar solo los pesos entrenados\n",
    "encoder.load_weights(\"/kaggle/working/encoder_11_26_h14_27.keras\")\n",
    "\n",
    "encoder.trainable=True\n",
    "siamese_model = build_siamese_network(encoder, (IMG_SIZE[0], IMG_SIZE[0], 3))\n",
    "siamese_model.compile(loss=\"binary_crossentropy\", optimizer=Adam(1e-5), metrics=[\"accuracy\"])\n",
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:39:52.344627Z",
     "iopub.status.busy": "2025-11-26T15:39:52.344260Z",
     "iopub.status.idle": "2025-11-26T15:40:09.752078Z",
     "shell.execute_reply": "2025-11-26T15:40:09.751347Z",
     "shell.execute_reply.started": "2025-11-26T15:39:52.344603Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def make_pairs_from_generator(generator):\n",
    "    \"\"\"\n",
    "    Crea pares de imágenes (positivos y negativos) a partir de un generator de Keras.\n",
    "    \n",
    "    Arguments:\n",
    "        generator: un ImageDataGenerator.flow_from_directory u otro generator que devuelva (x_batch, y_batch).\n",
    "    \n",
    "    Returns:\n",
    "        pairs: numpy array de shape (2*N, 2, H, W, C)\n",
    "        labels: numpy array binario de shape (2*N,)\n",
    "    \"\"\"\n",
    "    # --- 1. Extraer todas las imágenes y etiquetas del generator ---\n",
    "    all_images, all_labels = [], []\n",
    "    for i in range(len(generator)):\n",
    "        x_batch, y_batch = generator[i]\n",
    "        all_images.append(x_batch)\n",
    "        all_labels.append(np.argmax(y_batch, axis=1))  # convertir one-hot a entero\n",
    "    \n",
    "    x = np.concatenate(all_images, axis=0)\n",
    "    y = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # --- 2. Crear índices por clase ---\n",
    "    num_classes = np.max(y) + 1\n",
    "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
    "\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    # --- 3. Generar pares ---\n",
    "    for idx1 in range(len(x)):\n",
    "        x1 = x[idx1]\n",
    "        label1 = y[idx1]\n",
    "\n",
    "        # Par positivo (misma clase)\n",
    "        idx2 = random.choice(digit_indices[label1])\n",
    "        x2 = x[idx2]\n",
    "        pairs.append([x1, x2])\n",
    "        labels.append(1)  # aquí 1 = misma clase\n",
    "\n",
    "        # Par negativo (clase distinta)\n",
    "        label2 = random.randint(0, num_classes - 1)\n",
    "        while label2 == label1:\n",
    "            label2 = random.randint(0, num_classes - 1)\n",
    "        idx2 = random.choice(digit_indices[label2])\n",
    "        x2 = x[idx2]\n",
    "        pairs.append([x1, x2])\n",
    "        labels.append(0)  # aquí 0 = distinta clase\n",
    "\n",
    "    return np.array(pairs), np.array(labels).astype(\"float32\")\n",
    "\n",
    "pairs_train, labels_train = make_pairs_from_generator(train_generator)\n",
    "pairs_val, labels_val = make_pairs_from_generator(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T15:42:57.339716Z",
     "iopub.status.busy": "2025-11-26T15:42:57.338920Z",
     "iopub.status.idle": "2025-11-26T15:43:47.475869Z",
     "shell.execute_reply": "2025-11-26T15:43:47.474900Z",
     "shell.execute_reply.started": "2025-11-26T15:42:57.339690Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 319ms/step - accuracy: 0.5037 - loss: 0.6679 - val_accuracy: 0.5227 - val_loss: 0.6628\n",
      "Epoch 2/100\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 205ms/step - accuracy: 0.4992 - loss: 0.6591 - val_accuracy: 0.5227 - val_loss: 0.6604\n",
      "Epoch 3/100\n",
      "\u001b[1m35/53\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - accuracy: 0.4868 - loss: 0.6601"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47/822549303.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = siamese_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mpairs_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpairs_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = siamese_model.fit(\n",
    "    [pairs_train[:,0], pairs_train[:,1]], labels_train,\n",
    "    validation_data=([pairs_val[:,0], pairs_val[:,1]], labels_val),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=100\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8656484,
     "sourceId": 13877733,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "python3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
